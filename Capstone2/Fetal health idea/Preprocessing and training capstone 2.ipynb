{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01769da5",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "* [1.0 Purpose](#1.0)\n",
    "    * [1.1 Imports](#1.1)\n",
    "    * [1.2 Load the data](#1.2)\n",
    "    * [1.3 Inspect the data](#1.3)\n",
    "* [2.1 Proportion of classes](#2.1)\n",
    "    * [2.2 Dummy encoding](#2.2)\n",
    "* [3.1 Split dataframe into features and target](#3.1)\n",
    "    * [3.2 Preliminary modeling](#3.2)\n",
    "    * [3.3 Preliminary model confusion matrix and classification report](#3.3)\n",
    "* [4.0 Logistic regression model](#4.0)    \n",
    "    * [4.1 Tuning hyperparameters using a pipeline and GridSearchCV](#4.1)\n",
    "    * [4.2 Build a function to run GridSearchCV](#4.2)\n",
    "    * [4.3 Build a function to exclude highly correlated features](#4.3)\n",
    "    * [4.4 Recall results with \"hold out\" features to loop through](#4.4)\n",
    "    * [4.5 Individual model Recall results with excluded \"hold out\" features](#4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8c2bf2",
   "metadata": {},
   "source": [
    "##### 1.0 Purpose<a id='1.0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf3c1a",
   "metadata": {},
   "source": [
    "In the previous notebook, we completed exploratory data analysis. The data was visualized in terms of correlations, both between features and targets, and between features and other features.\n",
    "\n",
    "Now, in this notebook, we are in the preprocessing and training phase of this Capstone 2 project. We will be putting together different models for the training/testing process, then checking for accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80946f0e",
   "metadata": {},
   "source": [
    "##### 1.1 Imports<a id='1.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d41a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "#\n",
    "# plotting and visualization\n",
    "#\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import seaborn as sns\n",
    "#\n",
    "# modeling\n",
    "#\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ddeaf",
   "metadata": {},
   "source": [
    "##### 1.2 Load data<a id='1.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72bd6912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main data have  2126  rows and  22  columns\n",
      "\n",
      "column names: \n",
      "\n",
      "LB\n",
      "AC\n",
      "FM\n",
      "UC\n",
      "ASTV\n",
      "MSTV\n",
      "ALTV\n",
      "MLTV\n",
      "DL\n",
      "DS\n",
      "DP\n",
      "Width\n",
      "Min\n",
      "Max\n",
      "Nmax\n",
      "Nzeros\n",
      "Mode\n",
      "Mean\n",
      "Median\n",
      "Variance\n",
      "Tendency\n",
      "NSP\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\Joseph Shire\\Documents\\Springboard Python Data Science\\Python Scripts\\springboard\\Capstone2\\Fetal health idea'\n",
    "main_file = r'\\ctg_final.csv'\n",
    "df = pd.read_csv(path+main_file)\n",
    "fc = r'\\ctg_corr.csv'\n",
    "fcorr = pd.read_csv(path+fc)\n",
    "tc = r'\\ctg_corr_NSP.csv'\n",
    "tcorr = pd.read_csv(path+tc)\n",
    "\n",
    "print('The main data have ', df.shape[0], ' rows and ', df.shape[1], ' columns\\n')\n",
    "print('column names: \\n')\n",
    "print('\\n'.join(list(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ed659",
   "metadata": {},
   "source": [
    "Look at the correlation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3940720f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>correlation</th>\n",
       "      <th>abs_corr</th>\n",
       "      <th>corr_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DP</td>\n",
       "      <td>NSP_3.0</td>\n",
       "      <td>0.580253</td>\n",
       "      <td>0.580253</td>\n",
       "      <td>MID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASTV</td>\n",
       "      <td>NSP_1.0</td>\n",
       "      <td>-0.493391</td>\n",
       "      <td>0.493391</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALTV</td>\n",
       "      <td>NSP_1.0</td>\n",
       "      <td>-0.489400</td>\n",
       "      <td>0.489400</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NSP_3.0</td>\n",
       "      <td>Mode</td>\n",
       "      <td>-0.419051</td>\n",
       "      <td>0.419051</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALTV</td>\n",
       "      <td>NSP_2.0</td>\n",
       "      <td>0.418659</td>\n",
       "      <td>0.418659</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NSP_3.0</td>\n",
       "      <td>Mean</td>\n",
       "      <td>-0.416886</td>\n",
       "      <td>0.416886</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Median</td>\n",
       "      <td>NSP_3.0</td>\n",
       "      <td>-0.384857</td>\n",
       "      <td>0.384857</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AC</td>\n",
       "      <td>NSP_1.0</td>\n",
       "      <td>0.369470</td>\n",
       "      <td>0.369470</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NSP_2.0</td>\n",
       "      <td>ASTV</td>\n",
       "      <td>0.348213</td>\n",
       "      <td>0.348213</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LB</td>\n",
       "      <td>NSP_2.0</td>\n",
       "      <td>0.341922</td>\n",
       "      <td>0.341922</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_1    var_2  correlation  abs_corr corr_level\n",
       "0       DP  NSP_3.0     0.580253  0.580253        MID\n",
       "1     ASTV  NSP_1.0    -0.493391  0.493391        LOW\n",
       "2     ALTV  NSP_1.0    -0.489400  0.489400        LOW\n",
       "3  NSP_3.0     Mode    -0.419051  0.419051        LOW\n",
       "4     ALTV  NSP_2.0     0.418659  0.418659        LOW\n",
       "5  NSP_3.0     Mean    -0.416886  0.416886        LOW\n",
       "6   Median  NSP_3.0    -0.384857  0.384857        LOW\n",
       "7       AC  NSP_1.0     0.369470  0.369470        LOW\n",
       "8  NSP_2.0     ASTV     0.348213  0.348213        LOW\n",
       "9       LB  NSP_2.0     0.341922  0.341922        LOW"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcorr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9bd8aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>correlation</th>\n",
       "      <th>abs_corr</th>\n",
       "      <th>corr_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Median</td>\n",
       "      <td>Mean</td>\n",
       "      <td>0.948251</td>\n",
       "      <td>0.948251</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mode</td>\n",
       "      <td>Median</td>\n",
       "      <td>0.933399</td>\n",
       "      <td>0.933399</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Min</td>\n",
       "      <td>Width</td>\n",
       "      <td>-0.898519</td>\n",
       "      <td>0.898519</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mode</td>\n",
       "      <td>Mean</td>\n",
       "      <td>0.893412</td>\n",
       "      <td>0.893412</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LB</td>\n",
       "      <td>Median</td>\n",
       "      <td>0.789246</td>\n",
       "      <td>0.789246</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Width</td>\n",
       "      <td>Nmax</td>\n",
       "      <td>0.747071</td>\n",
       "      <td>0.747071</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mean</td>\n",
       "      <td>LB</td>\n",
       "      <td>0.723121</td>\n",
       "      <td>0.723121</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mode</td>\n",
       "      <td>LB</td>\n",
       "      <td>0.708993</td>\n",
       "      <td>0.708993</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Max</td>\n",
       "      <td>Width</td>\n",
       "      <td>0.690769</td>\n",
       "      <td>0.690769</td>\n",
       "      <td>MID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Min</td>\n",
       "      <td>Nmax</td>\n",
       "      <td>-0.670287</td>\n",
       "      <td>0.670287</td>\n",
       "      <td>MID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_1   var_2  correlation  abs_corr corr_level\n",
       "0  Median    Mean     0.948251  0.948251       HIGH\n",
       "1    Mode  Median     0.933399  0.933399       HIGH\n",
       "2     Min   Width    -0.898519  0.898519       HIGH\n",
       "3    Mode    Mean     0.893412  0.893412       HIGH\n",
       "4      LB  Median     0.789246  0.789246       HIGH\n",
       "5   Width    Nmax     0.747071  0.747071       HIGH\n",
       "6    Mean      LB     0.723121  0.723121       HIGH\n",
       "7    Mode      LB     0.708993  0.708993       HIGH\n",
       "8     Max   Width     0.690769  0.690769        MID\n",
       "9     Min    Nmax    -0.670287  0.670287        MID"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcorr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5f2aa2",
   "metadata": {},
   "source": [
    "##### 2.1 Proportion of classes<a id='2.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6090a565",
   "metadata": {},
   "source": [
    "When building classification models, it is essential to know right away the number of samples per class, proportionally to the total number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58298d",
   "metadata": {},
   "source": [
    "For our fetal health data, the diagnostic categories are: 1 = Normal = N, 2 = Suspect = S, 3 = Pathological = P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1af8246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw totals:\n",
      "\n",
      "1.0    1655\n",
      "2.0     295\n",
      "3.0     176\n",
      "Name: NSP, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts_nsp = df['NSP'].value_counts()\n",
    "print('Raw totals:\\n')\n",
    "print(class_counts_nsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cbd3545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentages:\n",
      "\n",
      "1    77.845720\n",
      "2    13.875823\n",
      "3     8.278457\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_p_nsp = pd.Series([(x / df.shape[0]) * 100.00 for x in class_counts_nsp], index=[1,2,3])\n",
    "print('Percentages:\\n')\n",
    "print(class_p_nsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5fb937",
   "metadata": {},
   "source": [
    "Visualize Proportionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "746ae9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(class_counts_nsp.index, class_counts_nsp)\n",
    "ax.set_xticks([1,2,3])\n",
    "ax.set_xticklabels(class_p_nsp.index.astype(str) + '\\n' + ' ' +\n",
    "                   class_p_nsp.round(2).astype(str) + '%')\n",
    "\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('NSP category')\n",
    "ax.set_title('Cardiotocogram NSP class distribution\\nwhere 1=normal; 2=suspect; 3=pathologic',\n",
    "              fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14195b55",
   "metadata": {},
   "source": [
    "##### 2.2 Dummy encode only categorical feature<a id='2.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce93d5",
   "metadata": {},
   "source": [
    "The feature \"Tendency\" is a categorical variable, and will need dummies applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb26d45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    1115\n",
       " 1.0     846\n",
       "-1.0     165\n",
       "Name: Tendency, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tendency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b245dc64",
   "metadata": {},
   "source": [
    "According to documentaiton, 'Tendency' is histogram tendency: -1=left assymetric; 0=symmetric; 1=right assymetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b521e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>NSP</th>\n",
       "      <th>Tendency_-1.0</th>\n",
       "      <th>Tendency_0.0</th>\n",
       "      <th>Tendency_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL   DS  ...  Nmax  \\\n",
       "0     120.0  0.0  0.0  0.0  73.0   0.5  43.0   2.4  0.0  0.0  ...   2.0   \n",
       "1     132.0  4.0  0.0  4.0  17.0   2.1   0.0  10.4  2.0  0.0  ...   6.0   \n",
       "2     133.0  2.0  0.0  5.0  16.0   2.1   0.0  13.4  2.0  0.0  ...   5.0   \n",
       "3     134.0  2.0  0.0  6.0  16.0   2.4   0.0  23.0  2.0  0.0  ...  11.0   \n",
       "4     132.0  4.0  0.0  5.0  16.0   2.4   0.0  19.9  0.0  0.0  ...   9.0   \n",
       "...     ...  ...  ...  ...   ...   ...   ...   ...  ...  ...  ...   ...   \n",
       "2121  140.0  0.0  0.0  6.0  79.0   0.2  25.0   7.2  0.0  0.0  ...   4.0   \n",
       "2122  140.0  1.0  0.0  9.0  78.0   0.4  22.0   7.1  0.0  0.0  ...   6.0   \n",
       "2123  140.0  1.0  0.0  7.0  79.0   0.4  20.0   6.1  0.0  0.0  ...   5.0   \n",
       "2124  140.0  1.0  0.0  9.0  78.0   0.4  27.0   7.0  0.0  0.0  ...   6.0   \n",
       "2125  142.0  1.0  1.0  5.0  74.0   0.4  36.0   5.0  0.0  0.0  ...   2.0   \n",
       "\n",
       "      Nzeros   Mode   Mean  Median  Variance  NSP  Tendency_-1.0  \\\n",
       "0        0.0  120.0  137.0   121.0      73.0  2.0              0   \n",
       "1        1.0  141.0  136.0   140.0      12.0  1.0              0   \n",
       "2        1.0  141.0  135.0   138.0      13.0  1.0              0   \n",
       "3        0.0  137.0  134.0   137.0      13.0  1.0              0   \n",
       "4        0.0  137.0  136.0   138.0      11.0  1.0              0   \n",
       "...      ...    ...    ...     ...       ...  ...            ...   \n",
       "2121     0.0  153.0  150.0   152.0       2.0  2.0              0   \n",
       "2122     0.0  152.0  148.0   151.0       3.0  2.0              0   \n",
       "2123     0.0  153.0  148.0   152.0       4.0  2.0              0   \n",
       "2124     0.0  152.0  147.0   151.0       4.0  2.0              0   \n",
       "2125     1.0  145.0  143.0   145.0       1.0  1.0              0   \n",
       "\n",
       "      Tendency_0.0  Tendency_1.0  \n",
       "0                0             1  \n",
       "1                1             0  \n",
       "2                1             0  \n",
       "3                0             1  \n",
       "4                0             1  \n",
       "...            ...           ...  \n",
       "2121             1             0  \n",
       "2122             0             1  \n",
       "2123             0             1  \n",
       "2124             0             1  \n",
       "2125             1             0  \n",
       "\n",
       "[2126 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfd = pd.get_dummies(df, columns = ['Tendency'])\n",
    "dfd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da02b337",
   "metadata": {},
   "source": [
    "##### 3.1 Split dataframe into features and target<a id='3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2e330",
   "metadata": {},
   "source": [
    "Setting our features as the X variable, and targets as the y variable for use in our modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c2643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    dfd['NSP'] = df['NSP'].replace([1.0,2.0,3.0],['N','S','P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f369ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfd.drop(columns = ['NSP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e9cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfd['NSP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad2b4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL   DS  ...    Max  Nmax  \\\n",
      "0  120.0  0.0  0.0  0.0  73.0   0.5  43.0   2.4  0.0  0.0  ...  126.0   2.0   \n",
      "1  132.0  4.0  0.0  4.0  17.0   2.1   0.0  10.4  2.0  0.0  ...  198.0   6.0   \n",
      "2  133.0  2.0  0.0  5.0  16.0   2.1   0.0  13.4  2.0  0.0  ...  198.0   5.0   \n",
      "3  134.0  2.0  0.0  6.0  16.0   2.4   0.0  23.0  2.0  0.0  ...  170.0  11.0   \n",
      "4  132.0  4.0  0.0  5.0  16.0   2.4   0.0  19.9  0.0  0.0  ...  170.0   9.0   \n",
      "\n",
      "   Nzeros   Mode   Mean  Median  Variance  Tendency_-1.0  Tendency_0.0  \\\n",
      "0     0.0  120.0  137.0   121.0      73.0              0             0   \n",
      "1     1.0  141.0  136.0   140.0      12.0              0             1   \n",
      "2     1.0  141.0  135.0   138.0      13.0              0             1   \n",
      "3     0.0  137.0  134.0   137.0      13.0              0             0   \n",
      "4     0.0  137.0  136.0   138.0      11.0              0             0   \n",
      "\n",
      "   Tendency_1.0  \n",
      "0             1  \n",
      "1             0  \n",
      "2             0  \n",
      "3             1  \n",
      "4             1  \n",
      "\n",
      "[5 rows x 23 columns] 0    S\n",
      "1    N\n",
      "2    N\n",
      "3    N\n",
      "4    N\n",
      "Name: NSP, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.head(),y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "63d1c60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    1655\n",
       "S     295\n",
       "P     176\n",
       "Name: NSP, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24881f",
   "metadata": {},
   "source": [
    "##### 3.2 Preliminary modeling<a id='3.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec5414",
   "metadata": {},
   "source": [
    "Start by training a single model on a single set of parameters, to see what non-tuned results might look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a564d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.80, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4fd18b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    1323\n",
       "S     236\n",
       "P     141\n",
       "Name: NSP, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fdd6a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    332\n",
       "S     59\n",
       "P     35\n",
       "Name: NSP, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c826c9",
   "metadata": {},
   "source": [
    "Using Logistic Regression, with the solver 'liblinear', maximum iterations set to 500, and regularization (C) at 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6a67b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'liblinear', max_iter = 500, C = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906bd75e",
   "metadata": {},
   "source": [
    "We fit the training data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "243a0f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, max_iter=500, solver='liblinear')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781ec97b",
   "metadata": {},
   "source": [
    "Then assess recall scores for training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "574c9ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on training data:  0.799235683107371\n"
     ]
    }
   ],
   "source": [
    "print('Recall on training data: ',recall_score(y_train,lr.predict(X_train), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19fbc57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall on test data:  0.7187928469325243\n"
     ]
    }
   ],
   "source": [
    "print(f'Recall on test data: ',recall_score(y_test,lr.predict(X_test),average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f533a59c",
   "metadata": {},
   "source": [
    "##### 3.3 Preliminary model confusion matrix and classification report<a id='3.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a923a143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1fe0cf524f0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(lr.predict(X_train), y_train)\n",
    "_, ax = plt.subplots()\n",
    "display_cm = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels=lr.classes_)\n",
    "ax.set_xticks([0, 2])\n",
    "ax.set_yticks([0, 2])\n",
    "display_cm.plot(ax = ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1f1dd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1fe0cf4c1c0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(lr.predict(X_test), y_test)\n",
    "_, ax = plt.subplots()\n",
    "display_cm = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels=lr.classes_)\n",
    "ax.set_xticks([0, 2])\n",
    "ax.set_yticks([0, 2])\n",
    "display_cm.plot(ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176889b1",
   "metadata": {},
   "source": [
    "Right away, we can see that for class P (pathological), this model is not satisfactory. The true positives of the test set equal 20, but class P false negatives add up to 9, which is only a class P identification rate of 20/(20+9) = 68.97%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7be89b",
   "metadata": {},
   "source": [
    "For a closer look at the performance, a classification report is created for both training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c6bf2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.94      0.96      0.95      1323\n",
      "           P       0.89      0.79      0.83       141\n",
      "           S       0.69      0.67      0.68       236\n",
      "\n",
      "    accuracy                           0.91      1700\n",
      "   macro avg       0.84      0.81      0.82      1700\n",
      "weighted avg       0.90      0.91      0.91      1700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, lr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2ea4e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.93      0.95      0.94       332\n",
      "           P       0.79      0.77      0.78        35\n",
      "           S       0.66      0.59      0.62        59\n",
      "\n",
      "    accuracy                           0.89       426\n",
      "   macro avg       0.80      0.77      0.78       426\n",
      "weighted avg       0.88      0.89      0.88       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6de14",
   "metadata": {},
   "source": [
    "The model performs better than randomly guessing, but there is much room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2858658",
   "metadata": {},
   "source": [
    "##### 4.0 Logistic regression model<a id='4.0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c73060e",
   "metadata": {},
   "source": [
    "Now we can commense hyperparameter tuning to get a better feel for what parameters could give us the best predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934b823",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a595b36",
   "metadata": {},
   "source": [
    "##### 4.1 Tuning hyperparameters using a pipeline and GridSearchCV<a id='4.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dd297c",
   "metadata": {},
   "source": [
    "Initially, we will look at a Logistic Regression model.\n",
    "The first step is to crete a pipeline. Within this step, we scale our data, since there are vastly differing scales among our features.\n",
    "Next, we include multiple levels of regularization (parameter 'C'), and multiple solvers.\n",
    "Finally, we use GridSearchCV to check recall scores across all combinations of the parameter choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5db4773",
   "metadata": {},
   "source": [
    "We will focus on recall for a scoring metric, due to class imbalance and the importance of reducing false negatives. The business interest lies in detecting pathological health conditions, so ensuring that Class P 'positives' are detected accurately is most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f02e07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:16:12.375019\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "#code to time\n",
    "\n",
    "steps = [(\"scaler\",StandardScaler()),(\"lr\",LogisticRegression(max_iter = 8000))]\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "Cval = [0.0001, 0.001, 0.1, 1, 5, 10, 50, 100]\n",
    "params = [{\"lr__penalty\":['none'], 'lr__solver': ['newton-cg','sag','lbfgs','saga']},{\"lr__penalty\":['l1'],\"lr__solver\":['liblinear','saga'],\"lr__C\":Cval},  {\"lr__penalty\":['l2'], 'lr__solver': ['liblinear','newton-cg','sag','lbfgs','saga'],\"lr__C\":Cval},{\"lr__penalty\":['elasticnet'],'lr__solver': ['saga'],'lr__l1_ratio':[0.2,0.5,0.8],\"lr__C\":Cval}]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params, scoring=\"recall_macro\")\n",
    "grid.fit(X_train, y_train)\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9136476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('lr',\n",
      "                 LogisticRegression(C=1, max_iter=8000, penalty='l1',\n",
      "                                    solver='saga'))]), {'lr__C': 1, 'lr__penalty': 'l1', 'lr__solver': 'saga'}, 0.8072552684831132]\n"
     ]
    }
   ],
   "source": [
    "best_results = [grid.best_estimator_, grid.best_params_, grid.best_score_]\n",
    "print(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52e9c78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "946461b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lr__solver</th>\n",
       "      <th>param_lr__penalty</th>\n",
       "      <th>param_lr__l1_ratio</th>\n",
       "      <th>param_lr__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_lr__solver param_lr__penalty param_lr__l1_ratio param_lr__C  \\\n",
       "11             saga                l1                NaN           1   \n",
       "\n",
       "    mean_test_score  \n",
       "11         0.807255  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = results.iloc[:,[5,4,7,6,14]].sort_values(results.columns[14], ascending=False)\n",
    "best_result = filtered.head(1)\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3766a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lr__solver</th>\n",
       "      <th>param_lr__penalty</th>\n",
       "      <th>param_lr__l1_ratio</th>\n",
       "      <th>param_lr__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>saga</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sag</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.804503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.804503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_lr__solver param_lr__penalty param_lr__l1_ratio param_lr__C  \\\n",
       "11             saga                l1                NaN           1   \n",
       "70             saga        elasticnet                0.5           1   \n",
       "40        liblinear                l2                NaN           5   \n",
       "42              sag                l2                NaN           5   \n",
       "44             saga                l2                NaN           5   \n",
       "\n",
       "    mean_test_score  \n",
       "11         0.807255  \n",
       "70         0.805586  \n",
       "40         0.805062  \n",
       "42         0.804503  \n",
       "44         0.804503  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a0a308e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'param_lr__solver'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = filtered.columns\n",
    "attributes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bbefc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saga'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = filtered[attributes[0]].iloc[0]\n",
    "solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd92b2dd",
   "metadata": {},
   "source": [
    "##### 4.2 Build a function to run GridSearchCV<a id='4.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b94f7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9144470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X,y,Cval=[0.0001, 0.001, 0.1, 1, 5, 10, 50, 100],scoring=\"recall_macro\",suppressCR=False):\n",
    "    \"\"\"\n",
    "    X is X_train\n",
    "    y is y_train\n",
    "    Cval is a list of C regularizations to be tried, auto covers a wide range\n",
    "    data is automatically scaled\n",
    "    suppressCR is whether you want the final readout to display the classification reports,\n",
    "        False means do display report, don't suppress it (default)\n",
    "        True means don't display report, suppress it\n",
    "    \n",
    "    Logistic regression only, max_iter = 8000\n",
    "    \"\"\"\n",
    "    #code to time how long this code runs for\n",
    "    start_timeLR = datetime.now()\n",
    "    \n",
    "    # create a pipeline for scaled data in logistic regression\n",
    "    steps = [(\"scaler\",StandardScaler()),(\"lr\",LogisticRegression(max_iter = 8000))]\n",
    "    pipe = Pipeline(steps)\n",
    "    \n",
    "    # list parameters to be tried in our grid search.\n",
    "    # all solvers at every penalty level included.\n",
    "    # Cval is implemented here (defult is wide range of C values).\n",
    "    params = [{\"lr__penalty\":['none'], 'lr__solver': ['newton-cg','sag','lbfgs','saga']},{\"lr__penalty\":['l1'],\"lr__solver\":['liblinear','saga'],\"lr__C\":Cval},  {\"lr__penalty\":['l2'], 'lr__solver': ['liblinear','newton-cg','sag','lbfgs','saga'],\"lr__C\":Cval},{\"lr__penalty\":['elasticnet'],'lr__solver': ['saga'],'lr__l1_ratio':[0.2,0.5,0.8],\"lr__C\":Cval}]\n",
    "    \n",
    "    # execute the grid search\n",
    "    grid = GridSearchCV(pipe, param_grid=params, scoring=scoring)\n",
    "    # fit the model\n",
    "    grid.fit(X, y)\n",
    "    # compile results in a dataframe\n",
    "    results = pd.DataFrame(grid.cv_results_)\n",
    "    # filter to only the desired columns and sort by performance\n",
    "    filtered = results.iloc[:,[5,4,7,6,14]].sort_values(results.columns[14], ascending=False)\n",
    "    filtered\n",
    "    \n",
    "    best_model = filtered.head(1)\n",
    "    attributes = best_model.columns\n",
    "    solver = best_model[attributes[0]].iloc[0]\n",
    "    penalty = best_model[attributes[1]].iloc[0]\n",
    "    l1_ratio = best_model[attributes[2]].iloc[0]\n",
    "    Creg = best_model[attributes[3]].iloc[0]\n",
    "    best_score = best_model[attributes[4]].iloc[0]\n",
    "\n",
    "    \n",
    "    if penalty == 'elasticnet':\n",
    "        print('solver = ', solver,', penalty = ', penalty,', C = ', Creg,'l1 ratio = ', l1_ratio)\n",
    "\n",
    "    else:\n",
    "        print('solver = ', solver,', penalty = ', penalty,', C = ', Creg)\n",
    "    print(scoring,' score = ', round(best_score,4),'\\n')\n",
    "    if suppressCR == False:\n",
    "        print('_______________________________________')\n",
    "\n",
    "        # run the best model and produce report\n",
    "        if penalty == 'elasticnet':    \n",
    "            best_model_lr = LogisticRegression(solver = solver, C = Creg, penalty=penalty, l1_ratio=l1_ratio, max_iter = 8000)\n",
    "            best_model_lr.fit(X, y)\n",
    "            print('Scoring = ',scoring)\n",
    "            print(\"Classification Report for Training Data (using the best-performing model)\")\n",
    "            print(classification_report(y, best_model_lr.predict(X)))\n",
    "            end_timeLR = datetime.now()\n",
    "            print('Duration of this segment: {}'.format(end_timeLR - start_timeLR))  \n",
    "        else:\n",
    "            best_model_lr = LogisticRegression(solver = solver, C = Creg, penalty=penalty, max_iter = 8000)\n",
    "            best_model_lr.fit(X, y)\n",
    "            print('Scoring = ',scoring)\n",
    "            print(\"Best Model Classification Report for Training Data\")\n",
    "            print(classification_report(y, best_model_lr.predict(X)))\n",
    "            end_timeLR = datetime.now()\n",
    "            print('Duration of this segment: {}'.format(end_timeLR - start_timeLR))  \n",
    "        print('*********************************************************\\n\\n')\n",
    "    else:\n",
    "        end_timeLR = datetime.now()\n",
    "        print('Duration of this segment: {}'.format(end_timeLR - start_timeLR))\n",
    "        print('*********************************************************\\n\\n')\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e85985",
   "metadata": {},
   "source": [
    "Test the function with simple parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4342146f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver =  saga , penalty =  l1 , C =  1\n",
      "recall_macro  score =  0.7987 \n",
      "\n",
      "_______________________________________\n",
      "Scoring =  recall_macro\n",
      "Best Model Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.93      0.95      0.94      1323\n",
      "           P       0.84      0.82      0.83       141\n",
      "           S       0.64      0.56      0.60       236\n",
      "\n",
      "    accuracy                           0.89      1700\n",
      "   macro avg       0.80      0.78      0.79      1700\n",
      "weighted avg       0.88      0.89      0.88      1700\n",
      "\n",
      "Duration of this segment: 0:01:12.666473\n",
      "*********************************************************\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lr__solver</th>\n",
       "      <th>param_lr__penalty</th>\n",
       "      <th>param_lr__l1_ratio</th>\n",
       "      <th>param_lr__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_lr__solver param_lr__penalty param_lr__l1_ratio param_lr__C  \\\n",
       "5             saga                l1                NaN           1   \n",
       "\n",
       "   mean_test_score  \n",
       "5         0.798661  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR(X_train,y_train,Cval=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd6354",
   "metadata": {},
   "source": [
    "##### 4.3 Build a function to exclude highly correlated features<a id='4.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76fc0f",
   "metadata": {},
   "source": [
    "To help resolve a potential issue with multicollinearity, we can see how our models perform when certain features are not included in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d9b806",
   "metadata": {},
   "source": [
    "Using another function, we can \"leave one out\" and run the Logistic Regression grid search repeatedly, in order to determine if excluding a highly colinear feature would be beneficial to the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7028dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_out(out,X,y,Cval=[0.0001, 0.001, 0.1, 1, 5, 10, 50, 100],scoring='recall_macro'):\n",
    "    \"\"\"\n",
    "    'out' is a list of the features in the training set,\n",
    "    of which one feature is excluded at a time.\n",
    "    \n",
    "    Previously defined function 'LR' is then looped through.\n",
    "    \"\"\"\n",
    "    \n",
    "    #code to time how long this code runs for\n",
    "    start_time = datetime.now()\n",
    "    choices = []\n",
    "\n",
    "    for i in out:\n",
    "        print('Best performing model with feature ',i,' held out')\n",
    "        best_model = LR(X.drop(columns=i),y,Cval,scoring,suppressCR=True)\n",
    "        # Note that 'suppressCR' is set to 'True'\n",
    "        # 'True' makes the final readout display only the best parameters,\n",
    "        # and not the classification reports.\n",
    "        \n",
    "        \n",
    "        attributes = best_model.columns\n",
    "        solver = best_model[attributes[0]].iloc[0]\n",
    "        penalty = best_model[attributes[1]].iloc[0]\n",
    "        l1_ratio = best_model[attributes[2]].iloc[0]\n",
    "        Creg = best_model[attributes[3]].iloc[0]\n",
    "        best_score = best_model[attributes[4]].iloc[0]\n",
    "        choices.append([i,solver,penalty,l1_ratio,Creg,best_score])\n",
    "        \n",
    "    df = pd.DataFrame(choices)\n",
    "    top = df.sort_values(df.columns[5], ascending=False)\n",
    "    top.columns = ['Excluded feature',attributes[0],attributes[1],attributes[2],attributes[3],attributes[4]]\n",
    "\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    print('Total Duration: {}'.format(end_time - start_time))  \n",
    "    return top\n",
    "    print(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1a196",
   "metadata": {},
   "source": [
    "Testing the nested functions with simple parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6746bb21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model with feature  Mean  held out\n",
      "solver =  saga , penalty =  l1 , C =  1\n",
      "recall_macro  score =  0.7931 \n",
      "\n",
      "Duration of this segment: 0:00:46.675361\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Best performing model with feature  Median  held out\n",
      "solver =  sag , penalty =  none , C =  nan\n",
      "recall_macro  score =  0.7939 \n",
      "\n",
      "Duration of this segment: 0:00:49.061346\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Total Duration: 0:01:35.740695\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Excluded feature</th>\n",
       "      <th>param_lr__solver</th>\n",
       "      <th>param_lr__penalty</th>\n",
       "      <th>param_lr__l1_ratio</th>\n",
       "      <th>param_lr__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Median</td>\n",
       "      <td>sag</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.793076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Excluded feature param_lr__solver param_lr__penalty  param_lr__l1_ratio  \\\n",
       "1           Median              sag              none                 NaN   \n",
       "0             Mean             saga                l1                 NaN   \n",
       "\n",
       "   param_lr__C  mean_test_score  \n",
       "1          NaN         0.793854  \n",
       "0          1.0         0.793076  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_out(['Mean','Median'],X_train,y_train,Cval=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d9654",
   "metadata": {},
   "source": [
    "##### 4.4 Recall results with \"hold out\" features to loop through<a id='4.4'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385a155",
   "metadata": {},
   "source": [
    "Of the 8 inter-feature correlations considered to have \"HIGH\" correlation, at least one of the features 'Mean', 'Median', 'Mode', and 'Width' always appears.\n",
    "Therefore, we will use the 'one_out' function to examine model performance while leaving one of these features out each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "625cdaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model with feature  Mean  held out\n",
      "solver =  saga , penalty =  l1 , C =  1\n",
      "recall_macro  score =  0.7931 \n",
      "\n",
      "Duration of this segment: 0:00:50.455536\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Best performing model with feature  Median  held out\n",
      "solver =  sag , penalty =  none , C =  nan\n",
      "recall_macro  score =  0.7939 \n",
      "\n",
      "Duration of this segment: 0:00:25.235757\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Best performing model with feature  Mode  held out\n",
      "solver =  saga , penalty =  l1 , C =  1\n",
      "recall_macro  score =  0.8 \n",
      "\n",
      "Duration of this segment: 0:00:26.467160\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Best performing model with feature  Width  held out\n",
      "solver =  saga , penalty =  l1 , C =  1\n",
      "recall_macro  score =  0.7987 \n",
      "\n",
      "Duration of this segment: 0:00:27.581111\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Total Duration: 0:02:09.747591\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Excluded feature</th>\n",
       "      <th>param_lr__solver</th>\n",
       "      <th>param_lr__penalty</th>\n",
       "      <th>param_lr__l1_ratio</th>\n",
       "      <th>param_lr__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mode</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Width</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Median</td>\n",
       "      <td>sag</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.793076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Excluded feature param_lr__solver param_lr__penalty  param_lr__l1_ratio  \\\n",
       "2             Mode             saga                l1                 NaN   \n",
       "3            Width             saga                l1                 NaN   \n",
       "1           Median              sag              none                 NaN   \n",
       "0             Mean             saga                l1                 NaN   \n",
       "\n",
       "   param_lr__C  mean_test_score  \n",
       "2          1.0         0.800028  \n",
       "3          1.0         0.798661  \n",
       "1          NaN         0.793854  \n",
       "0          1.0         0.793076  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_corr_feat = ['Mean','Median','Mode','Width']\n",
    "one_out(high_corr_feat,X_train,y_train,Cval=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da03e40",
   "metadata": {},
   "source": [
    "According to this function - and using recall as our performance measure - the best model among these 4 is \"excluding 'Mode'\", though it does not perform better than the best models on the previous no-hold-out training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d38dfc",
   "metadata": {},
   "source": [
    "To more completely assess which parameters will give us the best recall performance, we can run our 'one_out' function with the full array of C parameter options, which will allow us to decide which, if any, features should be held out for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23cdea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model with feature  Mean  held out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver =  saga , penalty =  l1 , C =  1\n",
      "recall_macro  score =  0.7931 \n",
      "\n",
      "Duration of this segment: 0:09:09.110282\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Best performing model with feature  Median  held out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver =  saga , penalty =  elasticnet , C =  10 l1 ratio =  0.5\n",
      "recall_macro  score =  0.7969 \n",
      "\n",
      "Duration of this segment: 0:05:57.391788\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Best performing model with feature  Mode  held out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver =  saga , penalty =  l1 , C =  1\n",
      "recall_macro  score =  0.8 \n",
      "\n",
      "Duration of this segment: 0:06:02.997336\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Best performing model with feature  Width  held out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver =  saga , penalty =  l2 , C =  5\n",
      "recall_macro  score =  0.8005 \n",
      "\n",
      "Duration of this segment: 0:05:59.818808\n",
      "*********************************************************\n",
      "\n",
      "\n",
      "Total Duration: 0:27:09.323202\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Excluded feature</th>\n",
       "      <th>param_lr__solver</th>\n",
       "      <th>param_lr__penalty</th>\n",
       "      <th>param_lr__l1_ratio</th>\n",
       "      <th>param_lr__C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Width</td>\n",
       "      <td>saga</td>\n",
       "      <td>l2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.800508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mode</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Median</td>\n",
       "      <td>saga</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.796913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean</td>\n",
       "      <td>saga</td>\n",
       "      <td>l1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.793076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Excluded feature param_lr__solver param_lr__penalty  param_lr__l1_ratio  \\\n",
       "3            Width             saga                l2                 NaN   \n",
       "2             Mode             saga                l1                 NaN   \n",
       "1           Median             saga        elasticnet                 0.5   \n",
       "0             Mean             saga                l1                 NaN   \n",
       "\n",
       "   param_lr__C  mean_test_score  \n",
       "3            5         0.800508  \n",
       "2            1         0.800028  \n",
       "1           10         0.796913  \n",
       "0            1         0.793076  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_out(high_corr_feat,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116caa76",
   "metadata": {},
   "source": [
    "##### 4.5 Individual model Recall results with excluded \"hold out\" features<a id='4.5'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8bd58",
   "metadata": {},
   "source": [
    "In order to maintain data continuity during individual model evaluation, we need to use scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b375ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sX_train = pd.DataFrame(sc.fit_transform(X_train),columns=X_train.columns)\n",
    "sX_test = pd.DataFrame(sc.transform(X_test),columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd34220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4954924",
   "metadata": {},
   "source": [
    "Remove just Mode and run a logistic regression on the training set, using top performing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d57104a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score =  0.8215564785035703\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.95      0.96      0.95      1323\n",
      "           P       0.90      0.83      0.86       141\n",
      "           S       0.69      0.68      0.68       236\n",
      "\n",
      "    accuracy                           0.91      1700\n",
      "   macro avg       0.85      0.82      0.83      1700\n",
      "weighted avg       0.91      0.91      0.91      1700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xMode = sX_train.drop(columns=['Mode'])\n",
    "lrs1 = LogisticRegression(solver = 'saga', max_iter = 8000, C = 1, penalty='l1')\n",
    "lrs1.fit(xMode, y_train)\n",
    "print('Recall score = ',recall_score(y_train, lrs1.predict(xMode),average='macro'))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, lrs1.predict(xMode)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944a43e",
   "metadata": {},
   "source": [
    "Compare Area Under the Receiver Operating Characteristic Curve (ROC AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "161a2583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740128168485302"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,lrs1.predict_proba(xMode),multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e1c5ab",
   "metadata": {},
   "source": [
    "Run a logistic regression using the same parameters on the training set without removing any feature (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d0d2e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score =  0.8201871618276405\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.95      0.96      0.95      1323\n",
      "           P       0.89      0.84      0.86       141\n",
      "           S       0.69      0.67      0.68       236\n",
      "\n",
      "    accuracy                           0.91      1700\n",
      "   macro avg       0.84      0.82      0.83      1700\n",
      "weighted avg       0.91      0.91      0.91      1700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrs2 = LogisticRegression(solver = 'saga', max_iter = 8000, C = 1, penalty='l1')\n",
    "lrs2.fit(sX_train, y_train)\n",
    "print('Recall score = ',recall_score(y_train, lrs2.predict(sX_train),average='macro'))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, lrs2.predict(sX_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d1ad9b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9743429138471565"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train,lrs2.predict_proba(sX_train),multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f7ae73",
   "metadata": {},
   "source": [
    "The training set excluding 'Mode' slightly outperforms the original set on recall: 0.82155 vs 0.82018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ec4ea",
   "metadata": {},
   "source": [
    "Run a logistic regression using the same parameters on the test set, excluding 'Mode' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "63a18f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score =  0.8414174859243269\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.96      0.97      0.96       332\n",
      "           P       0.88      0.83      0.85        35\n",
      "           S       0.74      0.73      0.74        59\n",
      "\n",
      "    accuracy                           0.92       426\n",
      "   macro avg       0.86      0.84      0.85       426\n",
      "weighted avg       0.92      0.92      0.92       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xModeTEST = sX_test.drop(columns=['Mode'])\n",
    "lrs3 = LogisticRegression(solver = 'saga', max_iter = 8000, C = 1, penalty='l1')\n",
    "lrs3.fit(xModeTEST, y_test)\n",
    "print('Recall score = ',recall_score(y_test, lrs3.predict(xModeTEST),average='macro'))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, lrs3.predict(xModeTEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "80954e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9779862090850969"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,lrs3.predict_proba(xModeTEST),multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ca0dd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score =  0.8128460573528983\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.95      0.97      0.96       332\n",
      "           P       0.87      0.74      0.80        35\n",
      "           S       0.73      0.73      0.73        59\n",
      "\n",
      "    accuracy                           0.92       426\n",
      "   macro avg       0.85      0.81      0.83       426\n",
      "weighted avg       0.91      0.92      0.91       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrs = LogisticRegression(solver = 'saga', max_iter = 8000, C = 1, penalty='l1')\n",
    "lrs.fit(sX_test, y_test)\n",
    "print('Recall score = ',recall_score(y_test, lrs.predict(sX_test),average='macro'))\n",
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, lrs.predict(sX_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "272a7554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788162432227919"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,lrs.predict_proba(sX_test),multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a057c7",
   "metadata": {},
   "source": [
    "Again, the test set excluding 'Mode' slightly outperforms the original set on recall: 0.8414 vs 0.8128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce596a45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ea7a0a3",
   "metadata": {},
   "source": [
    "Now we check on the neffect of removing both 'Width' and 'Mode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "33f6120d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score =  0.8229689078821014\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.95      0.96      0.95      1323\n",
      "           P       0.90      0.83      0.86       141\n",
      "           S       0.69      0.68      0.69       236\n",
      "\n",
      "    accuracy                           0.91      1700\n",
      "   macro avg       0.85      0.82      0.83      1700\n",
      "weighted avg       0.91      0.91      0.91      1700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xW = sX_train.drop(columns=['Mode','Width'])\n",
    "lrs5 = LogisticRegression(solver = 'saga', max_iter = 8000, C = 1, penalty='l1')\n",
    "lrs5.fit(xW, y_train)\n",
    "print('Recall score = ',recall_score(y_train, lrs5.predict(xW),average='macro'))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, lrs5.predict(xW)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8aec71b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score =  0.8414174859243269\n",
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.96      0.97      0.96       332\n",
      "           P       0.88      0.83      0.85        35\n",
      "           S       0.74      0.73      0.74        59\n",
      "\n",
      "    accuracy                           0.92       426\n",
      "   macro avg       0.86      0.84      0.85       426\n",
      "weighted avg       0.92      0.92      0.92       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xWtest = sX_test.drop(columns=['Mode','Width'])\n",
    "lrs6 = LogisticRegression(solver = 'saga', max_iter = 8000, C = 1, penalty='l1')\n",
    "lrs6.fit(xWtest, y_test)\n",
    "print('Recall score = ',recall_score(y_test, lrs6.predict(xWtest),average='macro'))\n",
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_test, lrs6.predict(xWtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "591ef091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9779862090850969"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,lrs6.predict_proba(xWtest),multi_class='ovr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9255b2f",
   "metadata": {},
   "source": [
    "These results seem to indicate that the removal of both 'Width' and 'Mode' from the features considered by the model, improve the recall performance thereof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9b44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204763e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c030ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b39c56d",
   "metadata": {},
   "source": [
    "(0) This is a very good notebook, but I suggest that you reorganize it so that in the \"Pre-Processing and Training\" part you only deal with one model--say LogisticRegression, and then use the results of that model to inform the decision of what models to use in the \"Modeling\" notebook, how many and how--in order to optimize what metric. The remaining comments aim at suggesting how to conduct this reorganization, by suggesting what to include in each notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a205997",
   "metadata": {},
   "source": [
    "(1) Pre-processing and Training: the goal is to use Logistic Regression (LogReg) to investigate: * Effect of the imbalance among the classes * Hyper-parameter tuning * Performance evaluation of models built * Identify what metric to optimize for, among: precision, recall, f-1, any other (e.g., business cost-based) * The effect of using highly correlated features * (Optional): the effect of using \"Leave one Out\" categorical encoding versus dummy variables (a) Just for fun, verify if the split produced by train/test split indeed preserved the size proportion among the classes for X_train, X_test, y_train, y_test--before building the first LogReg model.\n",
    "\n",
    "(b) You wrote: \"The model performs well, and even does better for the test set than the training set across the board (better precision, recall, and F1 scores for all 3 classes)\" There are two different types of evaluations we need to do here:\n",
    "(b.1) Is there overfitting? In order to determine this we compare the performance metrics of the classification reports for the training set and test set, pairwise: class 0 precision vs class 1 precision; class 0 recall vs class 1 recall; class 0 f-1 vs class 1 f-1. When you do that, you will see that your statement does not hold. Thus, in theory, one might want to try regularization, a.k.a. hyper-parameter tuning of parameter C with some details discussed below. \n",
    "(b.2) So, we want to do regularization due to the overfitting observed in (b.1) ... and you did that ... but ... \n",
    "(b.2.1) No need to include the long doc-page, just include a hyperlink to the doc page. \n",
    "(b.2.2) When doing regularization, one wants to shorten the gap between training performance and test performance, and in this case one would need to choose the metric that will be use in the GridSearch optimization, which is described by the parameter 'scoring'. Do you think that 'accuracy' would be appropriate? Why not precision, or recall, or f-1? Which one would you use based on the definition of precision, recall, and f-1 and the underlying business problem. Usually, choosing the appropriate metric is tied to the following question posed to the client: what are you able to better tolerate: (A) false positives, at the expense of having to deal with false negatives? (B) false negatives, at the expense of having to deal with false positives? (C) some compromise between (A) and (B) By using the answer/s from the client, you can then decide to optimize for precision, or recall, or f-1 (or some other ad-hoc metric that you would need to build to capture the requirements of your client.) \n",
    "(b.2.3) Think about whether you need to try different solvers? Would this make any difference with respect to the goal, which is to see if overfitting can be improved? \n",
    "(b.2.4) Notice that there are two types of regularization supported by LogisticRegression from scikit-learn. They should also be part of the list of hyper-parameters to be used ... https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html ... take a look at parameter 'penalty', which has default value of 'l2', which is usually referred to as \"L2-Regularization\". You can read the ISLR (*), chapter 6, and more specifically section 6.2. L2-regularization is also called \"Lasso\", and L1-Regularization is also called \"Ridge\". In conclusion, you can try with both values of this parameter ... penalty = ['l1', 'l2'] (*) https://hastie.su.domains/ISLR2/ISLRv2_website.pdf \n",
    "(c) Once you find the best mix of parameters for the perfomancce metric of choice, you can build the LogReg model for such mix and compare the performance of this model with respect to the previous one by using the classification report, as described above. Did the train/test gap diminish? \n",
    "(d) Also show the confusion matrices for both models (test set), and the ROC curves with AUC values. \n",
    "(e) Once you compare both models: >> Which one is the best model? >> Is there room for improvement? >> Is the room for improvement connected with the imbalance among the classes? >> What is the appropriate performance metric one would need to optimize for, in alignment with the business problem? \n",
    "(f) If you want to explore the effect of using highly correlated features, you can successively build LogReg models for all pairs (a, b) of features that are highly correlated such that you include one and not the other--perhaps randomly chosen. To simplify, you can use the same optimal hype-parameters from the analysis above. \n",
    "(g) If you want to explore the effect of using \"Leave one Out\" categorical encoding versus dummy variables, read about this by browsing some of the results of the Google search ... https://www.google.com/search?q=leave+one+out+encoding+sklearn&oq=leave+one+out+encoding+s&aqs=chrome.0.0i512j69i57j0i390.7896j0j15&sourceid=chrome&ie=UTF-8 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e7abda",
   "metadata": {},
   "source": [
    "(2) Modeling Notebook: In this notebook you want to use the notes I shared with you on imbalanced classification problems to combine a selection of over-sampling, and under-sampling techniques (implemented by package imblearn (+)) with classification algorithms, all of which would need hyper-parameter tuning: RandomForestClassifier, XGBOOST Classifier, LGBM Classifier (these are covered in case studies in the curriculum). Feel free to add more models, but be midnful of the multiplicative nature of combining N resampling techniques with M algorithms, which means building N * M models ... (+) https://imbalanced-learn.org/stable/ Some suggestions about this: \n",
    "(a) To avoid code repetition, you may want to create functions and pipelines to accomodate all these variations. \n",
    "(b) For hyper-parameter tuning, you would be optimizing for the performance metric chosen in the previous notebook \n",
    "(c) Continue to use classification report, confusion matrix, and ROC/AUC to evaluate the performance of the optimal models with respect to the **SAME** train/test split used in the Pre-Processing and Training notebook \n",
    "(d) Build a comparison table with **all** the models built at this point: combining the results from this notebook and the previous notebook \n",
    "(e) Analyze this comparison table: >> What is the best model and why? >> Are there opportunities to *combine* models, and how would you do this?--Reseach \"model ensembling\" After this, the next activity would be interpretability ... we can talk about this when we meet again ... Let me know if you have any questions ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

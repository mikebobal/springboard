{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting cab booking cancellation - Modeling<a id='1.0'></a>\n",
    "## Capstone Project 2 : Springboard Data Science Career Track\n",
    "### Michael Bobal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Table of Contents\n",
    "* [1.0 Capstone 2](#1.0)\n",
    "    * [1.1 Introduction](#1.1)\n",
    "    * [1.2 Purpose](#1.2)\n",
    "    * [1.3 Approach](#1.3)\n",
    "* [2.0 Data Overview](#2.0)            \n",
    "* [3.0 Import the necessary libraries and the data](#3.0)\n",
    "    * [3.1 Load the data](#3.1)\n",
    "* [4.0 Utilizing the data](#4.0)\n",
    "    * [4.1 Inspecting data](#4.1)\n",
    "    * [4.2 Eliminating excess info from the data](#4.2)\n",
    "    * [4.3 Pruning the data down to features and target](#4.3)\n",
    "    * [4.4 Grouping and aggregation](#4.4)\n",
    "    * [4.5 Encoding the categorical independent variable](#4.5)\n",
    "    * [4.6 Visualizing our target](#4.6)\n",
    "    * [4.7 Anonymizing the data by removing the identifying variable](#4.7)\n",
    "* [5.0 Begin modeling process](#5.0)\n",
    "    * [5.1 Split dataframe into features and target](#5.1)\n",
    "    * [5.2 Preliminary modeling](#5.2)\n",
    "    * [5.3 Scaling the data](#5.3)\n",
    "    * [5.4 Running a logistic regression model as a test](#5.4)\n",
    "* [6.0 Applying the Machine Learning models](#6.0)\n",
    "    * [6.1 Oversampling](#6.1)\n",
    "    * [6.2 Final realizations about the data](#6.2)\n",
    "* [7.0 Conclusions](#7.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Introduction: <a id='1.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Centers for Disease Control (CDC), in the United States, congenital heart defects (CHDs) are the most common types of birth defects. CHDs affect nearly 1% of children born, totalling nearly 40,000 cases per year. Of those 1% of children born with CHDs, about 25% have a critical CHD. Infants with critical CHDs will need surgery within their first year of life in order to prevent unnecessary death. Children in the fetal stage of development can also suffer from in-utero hypoxia - and even death - if certain fetal cardiac issues are not detected in time.\n",
    "\n",
    "Cardiotocography (CTG) is a non-invasive medical test used to assess fetal heart rhythm, as well as uterine contractions in the mother. Obstetricians use information acquired from CTG to assess fetal health, make determinations about the necessity of preventative C-sections, and inform parents about possible health issues which may require surgical intervention for the child.\n",
    "\n",
    "Currently, highly-trained physicians are required for the reading of CTG data, where they determine if the fetus’ CTG reading class (a.k.a. Fetal CTG Class) is normal, suspect, or pathologic (N, S, or P, respectively). An accurate determination is a critical step for parents, obstetricians, surgeons, and hospitals in terms of preparedness for medical intervention (C-section to save the life of the fetus, possible cardiac surgery in the first year of life after birth, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Purpose<a id='1.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac41816",
   "metadata": {},
   "source": [
    "Using CTG data obtained from the research paper, Ayres de Campos et al. [1], and the UCI Machine Learning Laboratory [2], we aim to build several models that can be trained to accurately predict the Fetal CTG Class from an input characterizing a CTG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3c33b",
   "metadata": {},
   "source": [
    "[1] Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318.\n",
    "\n",
    "[2] Ayres de Campos et al. (2000). UCI Machine Learning Repository . Irvine, CA: University of California, School of Information and Computer Science. https://archive.ics.uci.edu/ml/datasets/cardiotocography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b3e372",
   "metadata": {},
   "source": [
    "##### 1.3 Approach<a id='1.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ded218",
   "metadata": {},
   "source": [
    "The plan is to use several supervised machine learning algorithms to predict the classification of our main target, based on the features of the CTG reading:\n",
    "\n",
    "LB - FHR baseline (beats per minute)\n",
    "AC - # of accelerations per second\n",
    "FM - # of fetal movements per second\n",
    "UC - # of uterine contractions per second\n",
    "DL - # of light decelerations per second\n",
    "DS - # of severe decelerations per second\n",
    "DP - # of prolonged decelerations per second\n",
    "ASTV - percentage of time with abnormal short term variability\n",
    "MSTV - mean value of short term variability\n",
    "ALTV - percentage of time with abnormal long term variability\n",
    "MLTV - mean value of long term variability\n",
    "Width - width of FHR histogram\n",
    "Min - minimum of FHR histogram\n",
    "Max - Maximum of FHR histogram\n",
    "Nmax - # of histogram peaks\n",
    "Nzeros - # of histogram zeros\n",
    "Mode - histogram mode\n",
    "Mean - histogram mean\n",
    "Median - histogram median\n",
    "Variance - histogram variance\n",
    "Tendency - histogram tendency\n",
    "\n",
    "While the dependent variable will be our categorical target:\n",
    "NSP - Fetal CTG Class (N=normal; S=suspect; P=pathologic)\n",
    "\n",
    "The available dataset also provides an alternative target, known as the FHR Pattern Class Code, which is a number between 1 and 10. We will explore the use of this target as well.\n",
    "\n",
    "Multiple classification algorithms will be used and they will be compared with respect to appropriate performance metrics. We will also explore so-called ensemble methods [3, 4].\n",
    "\n",
    "Finally, we will explore some interpretability approaches to characterize how the variation of independent variables affect the target/s [5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d51f3",
   "metadata": {},
   "source": [
    "[3] https://machinelearningmastery.com/tour-of-ensemble-learning-algorithms/\n",
    "\n",
    "[4] https://sebastianraschka.com/pdf/lecture-notes/stat479fs18/07_ensembles_slides.pdf\n",
    "\n",
    "[5] https://christophm.github.io/interpretable-ml-book/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Data Overview<a id='2.0'></a>\n",
    "\n",
    "The plan is to use several supervised machine learning algorithms to predict the classification of our main target, based on the features of the CTG reading.\n",
    "\n",
    "The UCI Machine Learning Repository supplied this data.\n",
    "The features include the following:\n",
    "\n",
    "* LB - FHR baseline (beats per minute)\n",
    "* AC - # of accelerations per second\n",
    "* FM - # of fetal movements per second\n",
    "* UC - # of uterine contractions per second\n",
    "* DL - # of light decelerations per second\n",
    "* DS - # of severe decelerations per second\n",
    "* DP - # of prolonged decelerations per second\n",
    "* ASTV - percentage of time with abnormal short term variability\n",
    "* MSTV - mean value of short term variability\n",
    "* ALTV - percentage of time with abnormal long term variability\n",
    "* MLTV - mean value of long term variability\n",
    "* Width - width of FHR histogram\n",
    "* Min - minimum of FHR histogram\n",
    "* Max - Maximum of FHR histogram\n",
    "* Nmax - # of histogram peaks\n",
    "* Nzeros - # of histogram zeros\n",
    "* Mode - histogram mode\n",
    "* Mean - histogram mean\n",
    "* Median - histogram median\n",
    "* Variance - histogram variance\n",
    "* Tendency - histogram tendency\n",
    "\n",
    "The dependent variable will be our categorical target:\n",
    "* NSP - Fetal CTG Class:\n",
    "    * N=normal\n",
    "    * S=suspect\n",
    "    * P=pathologic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Import the necessary libraries and the data<a id='3.0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import all the necessary modules and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "from datetime import datetime\n",
    "#\n",
    "# plotting and visualization\n",
    "#\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import seaborn as sns\n",
    "#\n",
    "# modeling\n",
    "#\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#ignore warning messages to ensure clean outputs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Load the data<a id='3.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc3ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileloc = r'C:\\Users\\Joseph Shire\\Documents\\Springboard Python Data Science\\Python Scripts\\springboard\\Capstone2\\Fetal health idea\\CTG.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original file is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469ba65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our file for inspection\n",
    "file = pd.ExcelFile(fileloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have to select the proper sheet of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb659832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Description', 'Data', 'Raw Data']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect sheet names\n",
    "file.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a830ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the cardiotocography excel file, specifically the 'Raw Data' sheet\n",
    "ctg_file = pd.read_excel(fileloc, sheet_name = 'Raw Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 Utilizing the data<a id='4.0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we inspect the data, see what column names there are and what type of data each contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Inspecting data<a id='4.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d349217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2130 entries, 0 to 2129\n",
      "Data columns (total 40 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   FileName  2126 non-null   object        \n",
      " 1   Date      2126 non-null   datetime64[ns]\n",
      " 2   SegFile   2126 non-null   object        \n",
      " 3   b         2126 non-null   float64       \n",
      " 4   e         2126 non-null   float64       \n",
      " 5   LBE       2126 non-null   float64       \n",
      " 6   LB        2126 non-null   float64       \n",
      " 7   AC        2126 non-null   float64       \n",
      " 8   FM        2127 non-null   float64       \n",
      " 9   UC        2127 non-null   float64       \n",
      " 10  ASTV      2127 non-null   float64       \n",
      " 11  MSTV      2127 non-null   float64       \n",
      " 12  ALTV      2127 non-null   float64       \n",
      " 13  MLTV      2127 non-null   float64       \n",
      " 14  DL        2128 non-null   float64       \n",
      " 15  DS        2128 non-null   float64       \n",
      " 16  DP        2128 non-null   float64       \n",
      " 17  DR        2128 non-null   float64       \n",
      " 18  Width     2126 non-null   float64       \n",
      " 19  Min       2126 non-null   float64       \n",
      " 20  Max       2126 non-null   float64       \n",
      " 21  Nmax      2126 non-null   float64       \n",
      " 22  Nzeros    2126 non-null   float64       \n",
      " 23  Mode      2126 non-null   float64       \n",
      " 24  Mean      2126 non-null   float64       \n",
      " 25  Median    2126 non-null   float64       \n",
      " 26  Variance  2126 non-null   float64       \n",
      " 27  Tendency  2126 non-null   float64       \n",
      " 28  A         2126 non-null   float64       \n",
      " 29  B         2126 non-null   float64       \n",
      " 30  C         2126 non-null   float64       \n",
      " 31  D         2126 non-null   float64       \n",
      " 32  E         2126 non-null   float64       \n",
      " 33  AD        2126 non-null   float64       \n",
      " 34  DE        2126 non-null   float64       \n",
      " 35  LD        2126 non-null   float64       \n",
      " 36  FS        2126 non-null   float64       \n",
      " 37  SUSP      2126 non-null   float64       \n",
      " 38  CLASS     2126 non-null   float64       \n",
      " 39  NSP       2126 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(37), object(2)\n",
      "memory usage: 665.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# check the column names and data types\n",
    "ctg_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5edf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2130, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the shape of the data\n",
    "ctg_file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we visualize what the data looks like as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48b1d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Date</th>\n",
       "      <th>SegFile</th>\n",
       "      <th>b</th>\n",
       "      <th>e</th>\n",
       "      <th>LBE</th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>...</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>AD</th>\n",
       "      <th>DE</th>\n",
       "      <th>LD</th>\n",
       "      <th>FS</th>\n",
       "      <th>SUSP</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variab10.txt</td>\n",
       "      <td>1996-12-01</td>\n",
       "      <td>CTG0001.txt</td>\n",
       "      <td>240.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0002.txt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0003.txt</td>\n",
       "      <td>177.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0004.txt</td>\n",
       "      <td>411.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0005.txt</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fmcs_2.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0006.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fmcs_2.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0007.txt</td>\n",
       "      <td>240.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hasc_1.txt</td>\n",
       "      <td>1995-02-22</td>\n",
       "      <td>CTG0008.txt</td>\n",
       "      <td>62.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hasc_1.txt</td>\n",
       "      <td>1995-02-22</td>\n",
       "      <td>CTG0009.txt</td>\n",
       "      <td>120.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FileName       Date      SegFile      b       e    LBE     LB   AC  \\\n",
       "0           NaN        NaT          NaN    NaN     NaN    NaN    NaN  NaN   \n",
       "1  Variab10.txt 1996-12-01  CTG0001.txt  240.0   357.0  120.0  120.0  0.0   \n",
       "2    Fmcs_1.txt 1996-05-03  CTG0002.txt    5.0   632.0  132.0  132.0  4.0   \n",
       "3    Fmcs_1.txt 1996-05-03  CTG0003.txt  177.0   779.0  133.0  133.0  2.0   \n",
       "4    Fmcs_1.txt 1996-05-03  CTG0004.txt  411.0  1192.0  134.0  134.0  2.0   \n",
       "5    Fmcs_1.txt 1996-05-03  CTG0005.txt  533.0  1147.0  132.0  132.0  4.0   \n",
       "6    Fmcs_2.txt 1996-05-03  CTG0006.txt    0.0   953.0  134.0  134.0  1.0   \n",
       "7    Fmcs_2.txt 1996-05-03  CTG0007.txt  240.0   953.0  134.0  134.0  1.0   \n",
       "8    Hasc_1.txt 1995-02-22  CTG0008.txt   62.0   679.0  122.0  122.0  0.0   \n",
       "9    Hasc_1.txt 1995-02-22  CTG0009.txt  120.0   779.0  122.0  122.0  0.0   \n",
       "\n",
       "    FM    UC  ...    C    D    E   AD   DE   LD   FS  SUSP  CLASS  NSP  \n",
       "0  NaN   NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   NaN    NaN  NaN  \n",
       "1  0.0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  2.0  \n",
       "2  0.0   4.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
       "3  0.0   5.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
       "4  0.0   6.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
       "5  0.0   5.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    2.0  1.0  \n",
       "6  0.0  10.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0   0.0    8.0  3.0  \n",
       "7  0.0   9.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0   0.0    8.0  3.0  \n",
       "8  0.0   0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  3.0  \n",
       "9  0.0   1.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  3.0  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the data\n",
    "ctg_file.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already, we spy a row with 'NaN' values. Either way, we inspect the data to see the amount of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a5cf3c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FileName</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nzeros</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mode</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variance</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tendency</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUSP</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASS</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nmax</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SegFile</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBE</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSP</th>\n",
       "      <td>4</td>\n",
       "      <td>0.187793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSTV</th>\n",
       "      <td>3</td>\n",
       "      <td>0.140845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UC</th>\n",
       "      <td>3</td>\n",
       "      <td>0.140845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FM</th>\n",
       "      <td>3</td>\n",
       "      <td>0.140845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALTV</th>\n",
       "      <td>3</td>\n",
       "      <td>0.140845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLTV</th>\n",
       "      <td>3</td>\n",
       "      <td>0.140845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASTV</th>\n",
       "      <td>3</td>\n",
       "      <td>0.140845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>2</td>\n",
       "      <td>0.093897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DS</th>\n",
       "      <td>2</td>\n",
       "      <td>0.093897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DP</th>\n",
       "      <td>2</td>\n",
       "      <td>0.093897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR</th>\n",
       "      <td>2</td>\n",
       "      <td>0.093897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count         %\n",
       "FileName      4  0.187793\n",
       "Date          4  0.187793\n",
       "Nzeros        4  0.187793\n",
       "Mode          4  0.187793\n",
       "Mean          4  0.187793\n",
       "Median        4  0.187793\n",
       "Variance      4  0.187793\n",
       "Tendency      4  0.187793\n",
       "A             4  0.187793\n",
       "B             4  0.187793\n",
       "C             4  0.187793\n",
       "D             4  0.187793\n",
       "E             4  0.187793\n",
       "AD            4  0.187793\n",
       "DE            4  0.187793\n",
       "LD            4  0.187793\n",
       "FS            4  0.187793\n",
       "SUSP          4  0.187793\n",
       "CLASS         4  0.187793\n",
       "Nmax          4  0.187793\n",
       "Max           4  0.187793\n",
       "Min           4  0.187793\n",
       "Width         4  0.187793\n",
       "SegFile       4  0.187793\n",
       "b             4  0.187793\n",
       "e             4  0.187793\n",
       "LBE           4  0.187793\n",
       "LB            4  0.187793\n",
       "AC            4  0.187793\n",
       "NSP           4  0.187793\n",
       "MSTV          3  0.140845\n",
       "UC            3  0.140845\n",
       "FM            3  0.140845\n",
       "ALTV          3  0.140845\n",
       "MLTV          3  0.140845\n",
       "ASTV          3  0.140845\n",
       "DL            2  0.093897\n",
       "DS            2  0.093897\n",
       "DP            2  0.093897\n",
       "DR            2  0.093897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count missing values\n",
    "missing = pd.concat([ctg_file.isnull().sum(), 100 * ctg_file.isnull().mean()], axis=1)\n",
    "missing.columns=['count', '%']\n",
    "missing.sort_values(by=\"count\" ,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Date</th>\n",
       "      <th>SegFile</th>\n",
       "      <th>b</th>\n",
       "      <th>e</th>\n",
       "      <th>LBE</th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>...</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>AD</th>\n",
       "      <th>DE</th>\n",
       "      <th>LD</th>\n",
       "      <th>FS</th>\n",
       "      <th>SUSP</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>564.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FileName Date SegFile   b   e  LBE  LB  AC     FM    UC  ...   C   D   E  \\\n",
       "0         NaN  NaT     NaN NaN NaN  NaN NaN NaN    NaN   NaN  ... NaN NaN NaN   \n",
       "2127      NaN  NaT     NaN NaN NaN  NaN NaN NaN    NaN   NaN  ... NaN NaN NaN   \n",
       "2128      NaN  NaT     NaN NaN NaN  NaN NaN NaN    NaN   NaN  ... NaN NaN NaN   \n",
       "2129      NaN  NaT     NaN NaN NaN  NaN NaN NaN  564.0  23.0  ... NaN NaN NaN   \n",
       "\n",
       "      AD  DE  LD  FS  SUSP  CLASS  NSP  \n",
       "0    NaN NaN NaN NaN   NaN    NaN  NaN  \n",
       "2127 NaN NaN NaN NaN   NaN    NaN  NaN  \n",
       "2128 NaN NaN NaN NaN   NaN    NaN  NaN  \n",
       "2129 NaN NaN NaN NaN   NaN    NaN  NaN  \n",
       "\n",
       "[4 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nullF = ctg_file[ctg_file.isnull().any(axis=1)]\n",
    "nullF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c0369",
   "metadata": {},
   "source": [
    "This seems to be a case of \"extra values\" instead of \"missing values\" based on the uniformity of the missingness.\n",
    "All of the known important columns (FileName, Date, Mean/Median/Mode) are said to be 'missing' 4 values, so all columns should theoretically have 4 fewer values than the height of the data (2130).\n",
    "\n",
    "Threfore, we will remove any row not containing a file name, which is a logical choice as exclusion criteria (no file name = not included)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Eliminating excess info from the data<a id='4.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c6c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctg_file.drop(ctg_file[ctg_file[\"FileName\"].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ef61ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 40)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-check the shape to ensure it has 2126 rows\n",
    "ctg_file.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we visualize what the data looks like as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68b5056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Date</th>\n",
       "      <th>SegFile</th>\n",
       "      <th>b</th>\n",
       "      <th>e</th>\n",
       "      <th>LBE</th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>...</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>AD</th>\n",
       "      <th>DE</th>\n",
       "      <th>LD</th>\n",
       "      <th>FS</th>\n",
       "      <th>SUSP</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variab10.txt</td>\n",
       "      <td>1996-12-01</td>\n",
       "      <td>CTG0001.txt</td>\n",
       "      <td>240.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0002.txt</td>\n",
       "      <td>5.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0003.txt</td>\n",
       "      <td>177.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0004.txt</td>\n",
       "      <td>411.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1996-05-03</td>\n",
       "      <td>CTG0005.txt</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FileName       Date      SegFile      b       e    LBE     LB   AC  \\\n",
       "1  Variab10.txt 1996-12-01  CTG0001.txt  240.0   357.0  120.0  120.0  0.0   \n",
       "2    Fmcs_1.txt 1996-05-03  CTG0002.txt    5.0   632.0  132.0  132.0  4.0   \n",
       "3    Fmcs_1.txt 1996-05-03  CTG0003.txt  177.0   779.0  133.0  133.0  2.0   \n",
       "4    Fmcs_1.txt 1996-05-03  CTG0004.txt  411.0  1192.0  134.0  134.0  2.0   \n",
       "5    Fmcs_1.txt 1996-05-03  CTG0005.txt  533.0  1147.0  132.0  132.0  4.0   \n",
       "\n",
       "    FM   UC  ...    C    D    E   AD   DE   LD   FS  SUSP  CLASS  NSP  \n",
       "1  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   0.0    9.0  2.0  \n",
       "2  0.0  4.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
       "3  0.0  5.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
       "4  0.0  6.0  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   0.0    6.0  1.0  \n",
       "5  0.0  5.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    2.0  1.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize again\n",
    "ctg_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted in the previous notebook, there are repeat filenames with different data, which turned out to be the same patient receiving the CTG testing multiple times on a single day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg_file[\"FileName\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of unique files (352) will be our indication of the true number of patients in this dataset of 2126 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that scale of reduction in data, how many times was the CTG test repeated per patient? In order to find out, we counted how many occurances of each filename exist in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S8001034.dsp</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7001029.dsp</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S8001037.dsp</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S8001038.dsp</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7001027.dsp</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7001006.dsp</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7001008.dsp</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mepfp_3.txt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrmmf_1.txt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variab10.txt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              count\n",
       "S8001034.dsp     34\n",
       "S7001029.dsp     33\n",
       "S8001037.dsp     30\n",
       "S8001038.dsp     26\n",
       "S7001027.dsp     24\n",
       "...             ...\n",
       "S7001006.dsp      1\n",
       "S7001008.dsp      1\n",
       "Mepfp_3.txt       1\n",
       "Mrmmf_1.txt       1\n",
       "Variab10.txt      1\n",
       "\n",
       "[352 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnvc = pd.DataFrame(ctg_file[\"FileName\"].value_counts()).rename(columns={'FileName': 'count'})\n",
    "fnvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize 352 rows, a table is less useful than a graph, so we use a bar graph of the frequency of each total number of tests per patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(fnvc, bins=max(fnvc['count']))\n",
    "plt.xlabel(\"Number of datapoints from single patient\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of test counts per patient is vast, with a plurality of patients receiving 2 CTG tests, and most of the patients receiving 6 or fewer. However, even with this leftward skew, there are still some patients who had the CTG test repeated 30 or more times!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to find a proper way to aggregate each patients' multiple datapoints into single datapoints, but first, we need to eliminate unnecessary columns in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Pruning the data down to features and target<a id='4.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variab10.txt</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FileName     LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL  ...   Min  \\\n",
       "1  Variab10.txt  120.0  0.0  0.0  0.0  73.0   0.5  43.0   2.4  0.0  ...  62.0   \n",
       "2    Fmcs_1.txt  132.0  4.0  0.0  4.0  17.0   2.1   0.0  10.4  2.0  ...  68.0   \n",
       "3    Fmcs_1.txt  133.0  2.0  0.0  5.0  16.0   2.1   0.0  13.4  2.0  ...  68.0   \n",
       "4    Fmcs_1.txt  134.0  2.0  0.0  6.0  16.0   2.4   0.0  23.0  2.0  ...  53.0   \n",
       "5    Fmcs_1.txt  132.0  4.0  0.0  5.0  16.0   2.4   0.0  19.9  0.0  ...  53.0   \n",
       "\n",
       "     Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  NSP  \n",
       "1  126.0   2.0     0.0  120.0  137.0   121.0      73.0       1.0  2.0  \n",
       "2  198.0   6.0     1.0  141.0  136.0   140.0      12.0       0.0  1.0  \n",
       "3  198.0   5.0     1.0  141.0  135.0   138.0      13.0       0.0  1.0  \n",
       "4  170.0  11.0     0.0  137.0  134.0   137.0      13.0       1.0  1.0  \n",
       "5  170.0   9.0     0.0  137.0  136.0   138.0      11.0       1.0  1.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut = [\"Date\",\"b\",\"e\",\"LBE\",\"DR\",\"SegFile\",\"A\",\"B\",\"C\",\"D\",\"E\",\"AD\",\"DE\",\"LD\",\"FS\",\"SUSP\",\"CLASS\"]\n",
    "\n",
    "ctg = ctg_file.loc[:, ~ctg_file.columns.isin(cut)]\n",
    "ctg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Grouping and aggregation<a id='4.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seperate columns representing numbers from columns representing categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>...</th>\n",
       "      <th>DP</th>\n",
       "      <th>Width</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variab10.txt</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FileName     LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL  ...   DP  \\\n",
       "1  Variab10.txt  120.0  0.0  0.0  0.0  73.0   0.5  43.0   2.4  0.0  ...  0.0   \n",
       "2    Fmcs_1.txt  132.0  4.0  0.0  4.0  17.0   2.1   0.0  10.4  2.0  ...  0.0   \n",
       "3    Fmcs_1.txt  133.0  2.0  0.0  5.0  16.0   2.1   0.0  13.4  2.0  ...  0.0   \n",
       "4    Fmcs_1.txt  134.0  2.0  0.0  6.0  16.0   2.4   0.0  23.0  2.0  ...  0.0   \n",
       "5    Fmcs_1.txt  132.0  4.0  0.0  5.0  16.0   2.4   0.0  19.9  0.0  ...  0.0   \n",
       "\n",
       "   Width   Min    Max  Nmax  Nzeros   Mode   Mean  Median  Variance  \n",
       "1   64.0  62.0  126.0   2.0     0.0  120.0  137.0   121.0      73.0  \n",
       "2  130.0  68.0  198.0   6.0     1.0  141.0  136.0   140.0      12.0  \n",
       "3  130.0  68.0  198.0   5.0     1.0  141.0  135.0   138.0      13.0  \n",
       "4  117.0  53.0  170.0  11.0     0.0  137.0  134.0   137.0      13.0  \n",
       "5  117.0  53.0  170.0   9.0     0.0  137.0  136.0   138.0      11.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ctg.iloc[:,list(range(0,21))]\n",
    "cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variab10.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fmcs_1.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FileName  Tendency  NSP\n",
       "1  Variab10.txt       1.0  2.0\n",
       "2    Fmcs_1.txt       0.0  1.0\n",
       "3    Fmcs_1.txt       0.0  1.0\n",
       "4    Fmcs_1.txt       1.0  1.0\n",
       "5    Fmcs_1.txt       1.0  1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ctg.iloc[:,[0,-2,-1]]\n",
    "cat_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will aggregate the instances of multiple data points for each single patient using the mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the numeric data, the average of each feature will be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the categorical data, the encoding is ordinal: each successive gradation is a different value on a scale. Therefore, we can actually take the mean of each variable, and round to the nearest whole number.\n",
    "For example, if, among 4 tests, 'NSP' values are 1, 1, 1, 2, then the NSP average for that subject would be 1.25.\n",
    "Rounding to the nearest whole number puts the aggregate value to be used in our modeling at 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we complete this step by using 'FileName' as the grouping column, and taking the mean of each value, rounding only the categorical (ordinal) variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aast_1.txt</th>\n",
       "      <td>119.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.555556</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>10.433333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.777778</td>\n",
       "      <td>132.666667</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>122.888889</td>\n",
       "      <td>121.666667</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aast_10.txt</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.818182</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>12.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.636364</td>\n",
       "      <td>142.454545</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.636364</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>129.818182</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aast_11.txt</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>8.633333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.666667</td>\n",
       "      <td>138.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.666667</td>\n",
       "      <td>127.666667</td>\n",
       "      <td>128.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aast_12.txt</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>59.333333</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.666667</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>124.333333</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aast_13.txt</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tffm_2.txt</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tffm_3.txt</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.600000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>126.200000</td>\n",
       "      <td>125.800000</td>\n",
       "      <td>126.800000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tffm_4.txt</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tffm_5.txt</th>\n",
       "      <td>119.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.333333</td>\n",
       "      <td>175.666667</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>124.333333</td>\n",
       "      <td>125.333333</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variab10.txt</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      LB         AC        FM        UC       ASTV      MSTV  \\\n",
       "FileName                                                                       \n",
       "Aast_1.txt    119.333333   0.111111  8.000000  0.000000  53.555556  0.655556   \n",
       "Aast_10.txt   123.000000   1.727273  2.363636  0.000000  51.818182  0.790909   \n",
       "Aast_11.txt   121.000000   2.666667  4.000000  0.000000  55.333333  0.566667   \n",
       "Aast_12.txt   125.000000   0.000000  4.666667  0.666667  67.000000  0.300000   \n",
       "Aast_13.txt   125.000000   0.000000  4.000000  1.000000  68.000000  0.400000   \n",
       "...                  ...        ...       ...       ...        ...       ...   \n",
       "Tffm_2.txt    124.000000  10.000000  0.000000  6.000000  34.000000  1.000000   \n",
       "Tffm_3.txt    123.000000   0.800000  0.000000  0.400000  39.000000  0.960000   \n",
       "Tffm_4.txt    123.000000   0.500000  0.000000  3.500000  52.000000  0.500000   \n",
       "Tffm_5.txt    119.333333   3.666667  0.000000  7.666667  49.000000  1.666667   \n",
       "Variab10.txt  120.000000   0.000000  0.000000  0.000000  73.000000  0.500000   \n",
       "\n",
       "                   ALTV       MLTV        DL   DS  ...         Min  \\\n",
       "FileName                                           ...               \n",
       "Aast_1.txt     8.333333  10.433333  0.111111  0.0  ...   85.777778   \n",
       "Aast_10.txt    3.272727  12.818182  0.000000  0.0  ...   64.636364   \n",
       "Aast_11.txt    2.666667   8.633333  0.000000  0.0  ...   98.666667   \n",
       "Aast_12.txt   59.333333   4.733333  0.000000  0.0  ...  115.666667   \n",
       "Aast_13.txt   24.500000   6.900000  0.500000  0.0  ...   80.500000   \n",
       "...                 ...        ...       ...  ...  ...         ...   \n",
       "Tffm_2.txt     0.000000   2.000000  0.500000  0.0  ...  108.000000   \n",
       "Tffm_3.txt    14.200000  12.000000  0.000000  0.0  ...   61.600000   \n",
       "Tffm_4.txt     8.500000   8.000000  0.000000  0.0  ...  116.000000   \n",
       "Tffm_5.txt     6.666667   7.533333  1.333333  0.0  ...   53.333333   \n",
       "Variab10.txt  43.000000   2.400000  0.000000  0.0  ...   62.000000   \n",
       "\n",
       "                     Max      Nmax    Nzeros        Mode        Mean  \\\n",
       "FileName                                                               \n",
       "Aast_1.txt    132.666667  2.777778  0.222222  122.888889  121.666667   \n",
       "Aast_10.txt   142.454545  4.818182  0.000000  128.636364  128.000000   \n",
       "Aast_11.txt   138.666667  1.000000  0.000000  125.666667  127.666667   \n",
       "Aast_12.txt   130.000000  0.333333  0.000000  125.000000  124.333333   \n",
       "Aast_13.txt   132.000000  3.000000  0.000000  122.500000  122.000000   \n",
       "...                  ...       ...       ...         ...         ...   \n",
       "Tffm_2.txt    148.500000  2.000000  0.000000  127.500000  130.000000   \n",
       "Tffm_3.txt    143.000000  4.800000  0.200000  126.200000  125.800000   \n",
       "Tffm_4.txt    141.000000  2.500000  0.000000  126.000000  127.000000   \n",
       "Tffm_5.txt    175.666667  7.666667  0.666667  124.333333  125.333333   \n",
       "Variab10.txt  126.000000  2.000000  0.000000  120.000000  137.000000   \n",
       "\n",
       "                  Median   Variance  Tendency  NSP  \n",
       "FileName                                            \n",
       "Aast_1.txt    123.333333   1.555556       0.0  1.0  \n",
       "Aast_10.txt   129.818182   3.545455       1.0  1.0  \n",
       "Aast_11.txt   128.666667   2.666667       0.0  1.0  \n",
       "Aast_12.txt   126.000000   0.000000       0.0  2.0  \n",
       "Aast_13.txt   123.500000   1.500000       0.0  2.0  \n",
       "...                  ...        ...       ...  ...  \n",
       "Tffm_2.txt    130.500000   6.000000       0.0  1.0  \n",
       "Tffm_3.txt    126.800000   2.800000       1.0  1.0  \n",
       "Tffm_4.txt    128.000000   2.000000       0.0  1.0  \n",
       "Tffm_5.txt    127.000000  13.666667       0.0  1.0  \n",
       "Variab10.txt  121.000000  73.000000       1.0  2.0  \n",
       "\n",
       "[352 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg_mean = cols.groupby(\"FileName\").agg('mean',numeric_only=True)\n",
    "ctg_cat = cat_cols.groupby(\"FileName\").agg('mean')\n",
    "ctg_cat = ctg_cat.round(0)\n",
    "ctg_fe = pd.concat([ctg_mean,ctg_cat],axis=1)\n",
    "ctg_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5 Encoding the categorical independent variable<a id='4.5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    211\n",
       " 1.0    127\n",
       "-1.0     14\n",
       "Name: Tendency, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctg_fe['Tendency'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature \"Tendency\" is a categorical variable, and will need dummies applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>NSP</th>\n",
       "      <th>Tendency_0.0</th>\n",
       "      <th>Tendency_1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aast_1.txt</th>\n",
       "      <td>119.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.555556</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>10.433333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>132.666667</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>122.888889</td>\n",
       "      <td>121.666667</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aast_10.txt</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.818182</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>12.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.454545</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.636364</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>129.818182</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aast_11.txt</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>8.633333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>138.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.666667</td>\n",
       "      <td>127.666667</td>\n",
       "      <td>128.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aast_12.txt</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>59.333333</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>124.333333</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aast_13.txt</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>122.500000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tffm_2.txt</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tffm_3.txt</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>126.200000</td>\n",
       "      <td>125.800000</td>\n",
       "      <td>126.800000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tffm_4.txt</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tffm_5.txt</th>\n",
       "      <td>119.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.533333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>175.666667</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>124.333333</td>\n",
       "      <td>125.333333</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variab10.txt</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      LB         AC        FM        UC       ASTV      MSTV  \\\n",
       "FileName                                                                       \n",
       "Aast_1.txt    119.333333   0.111111  8.000000  0.000000  53.555556  0.655556   \n",
       "Aast_10.txt   123.000000   1.727273  2.363636  0.000000  51.818182  0.790909   \n",
       "Aast_11.txt   121.000000   2.666667  4.000000  0.000000  55.333333  0.566667   \n",
       "Aast_12.txt   125.000000   0.000000  4.666667  0.666667  67.000000  0.300000   \n",
       "Aast_13.txt   125.000000   0.000000  4.000000  1.000000  68.000000  0.400000   \n",
       "...                  ...        ...       ...       ...        ...       ...   \n",
       "Tffm_2.txt    124.000000  10.000000  0.000000  6.000000  34.000000  1.000000   \n",
       "Tffm_3.txt    123.000000   0.800000  0.000000  0.400000  39.000000  0.960000   \n",
       "Tffm_4.txt    123.000000   0.500000  0.000000  3.500000  52.000000  0.500000   \n",
       "Tffm_5.txt    119.333333   3.666667  0.000000  7.666667  49.000000  1.666667   \n",
       "Variab10.txt  120.000000   0.000000  0.000000  0.000000  73.000000  0.500000   \n",
       "\n",
       "                   ALTV       MLTV        DL   DS  ...         Max      Nmax  \\\n",
       "FileName                                           ...                         \n",
       "Aast_1.txt     8.333333  10.433333  0.111111  0.0  ...  132.666667  2.777778   \n",
       "Aast_10.txt    3.272727  12.818182  0.000000  0.0  ...  142.454545  4.818182   \n",
       "Aast_11.txt    2.666667   8.633333  0.000000  0.0  ...  138.666667  1.000000   \n",
       "Aast_12.txt   59.333333   4.733333  0.000000  0.0  ...  130.000000  0.333333   \n",
       "Aast_13.txt   24.500000   6.900000  0.500000  0.0  ...  132.000000  3.000000   \n",
       "...                 ...        ...       ...  ...  ...         ...       ...   \n",
       "Tffm_2.txt     0.000000   2.000000  0.500000  0.0  ...  148.500000  2.000000   \n",
       "Tffm_3.txt    14.200000  12.000000  0.000000  0.0  ...  143.000000  4.800000   \n",
       "Tffm_4.txt     8.500000   8.000000  0.000000  0.0  ...  141.000000  2.500000   \n",
       "Tffm_5.txt     6.666667   7.533333  1.333333  0.0  ...  175.666667  7.666667   \n",
       "Variab10.txt  43.000000   2.400000  0.000000  0.0  ...  126.000000  2.000000   \n",
       "\n",
       "                Nzeros        Mode        Mean      Median   Variance  NSP  \\\n",
       "FileName                                                                     \n",
       "Aast_1.txt    0.222222  122.888889  121.666667  123.333333   1.555556  1.0   \n",
       "Aast_10.txt   0.000000  128.636364  128.000000  129.818182   3.545455  1.0   \n",
       "Aast_11.txt   0.000000  125.666667  127.666667  128.666667   2.666667  1.0   \n",
       "Aast_12.txt   0.000000  125.000000  124.333333  126.000000   0.000000  2.0   \n",
       "Aast_13.txt   0.000000  122.500000  122.000000  123.500000   1.500000  2.0   \n",
       "...                ...         ...         ...         ...        ...  ...   \n",
       "Tffm_2.txt    0.000000  127.500000  130.000000  130.500000   6.000000  1.0   \n",
       "Tffm_3.txt    0.200000  126.200000  125.800000  126.800000   2.800000  1.0   \n",
       "Tffm_4.txt    0.000000  126.000000  127.000000  128.000000   2.000000  1.0   \n",
       "Tffm_5.txt    0.666667  124.333333  125.333333  127.000000  13.666667  1.0   \n",
       "Variab10.txt  0.000000  120.000000  137.000000  121.000000  73.000000  2.0   \n",
       "\n",
       "              Tendency_0.0  Tendency_1.0  \n",
       "FileName                                  \n",
       "Aast_1.txt               1             0  \n",
       "Aast_10.txt              0             1  \n",
       "Aast_11.txt              1             0  \n",
       "Aast_12.txt              1             0  \n",
       "Aast_13.txt              1             0  \n",
       "...                    ...           ...  \n",
       "Tffm_2.txt               1             0  \n",
       "Tffm_3.txt               0             1  \n",
       "Tffm_4.txt               1             0  \n",
       "Tffm_5.txt               1             0  \n",
       "Variab10.txt             0             1  \n",
       "\n",
       "[352 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(ctg_fe, columns = ['Tendency'], drop_first=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target 'NSP' contains 3 variables: 1 for Normal CTG, 2 for Suspect CTG, 3 for Pathological CTG. We will replace the numbers with letters designating which category each datapoint belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NSP'] = df['NSP'].replace({1.0:'N',2.0:'S',3.0:'P'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6 Visualizing our target<a id='4.6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsp = ['N','S','P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_nsp = df['NSP'].value_counts()\n",
    "class_p_nsp = pd.Series([(x / df.shape[0]) * 100.00 for x in class_counts_nsp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(class_counts_nsp.index, class_counts_nsp)\n",
    "ax.set_xticks([0,1,2])\n",
    "\n",
    "a=ax.get_xticks().tolist()\n",
    "for i in a:    \n",
    "    a[i] = nsp[i]+'\\n' + class_p_nsp.round(2).astype(str)[i] + '%'+'\\n' +'n = '+class_counts_nsp.astype(str)[i]\n",
    "ax.set_xticklabels(a)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Cardiotocogram NSP class distribution',\n",
    "              fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the nature of health sciences having the main purpose of supporting well-being of patients, we have determined to eliminate the \"Suspect\" class from our initial analysis. At-risk fetuses are either in health danger (Pathological class), or not (Normal class). In this notebook, we will endeavour to reclassify these 91 patients into one of the binary classes of Normal or Pathological, and inspect the results through graphical visualizations.\n",
    "\n",
    "Having made this determination, we will thus remove \"S\" class datapoints from our data during this preprocessing step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    238\n",
       "P     23\n",
       "Name: NSP, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df['NSP'] != 'S']\n",
    "df2['NSP'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the S class for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_class = df[df['NSP'] == 'S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the target as it will be in our main analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_np = df2['NSP'].value_counts()\n",
    "class_p_np = pd.Series([(x / df2.shape[0]) * 100.00 for x in class_counts_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsp = ['N','P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(class_counts_np.index, class_counts_np)\n",
    "ax.set_xticks([0,1])\n",
    "\n",
    "a=ax.get_xticks().tolist()\n",
    "for i in a:\n",
    "        a[i] = nsp[i]+'\\n' + class_p_np.round(2).astype(str)[i] + '%'+'\\n' +'n = '+class_counts_np.astype(str)[i]\n",
    "ax.set_xticklabels(a)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Cardiotocogram NP class distribution',\n",
    "              fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.7 Anonymizing the data by removing the identifying variable<a id='4.7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>NSP</th>\n",
       "      <th>Tendency_0.0</th>\n",
       "      <th>Tendency_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.555556</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>10.433333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>132.666667</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>122.888889</td>\n",
       "      <td>121.666667</td>\n",
       "      <td>123.333333</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.818182</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>12.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.454545</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.636364</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>129.818182</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>8.633333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>138.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.666667</td>\n",
       "      <td>127.666667</td>\n",
       "      <td>128.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LB        AC         FM   UC       ASTV      MSTV      ALTV  \\\n",
       "0  119.333333  0.111111   8.000000  0.0  53.555556  0.655556  8.333333   \n",
       "1  123.000000  1.727273   2.363636  0.0  51.818182  0.790909  3.272727   \n",
       "2  121.000000  2.666667   4.000000  0.0  55.333333  0.566667  2.666667   \n",
       "3  120.000000  0.000000   8.500000  0.0  54.000000  0.850000  0.000000   \n",
       "4  124.000000  3.000000  10.000000  1.0  46.000000  0.800000  0.000000   \n",
       "\n",
       "        MLTV        DL   DS  ...         Max      Nmax    Nzeros        Mode  \\\n",
       "0  10.433333  0.111111  0.0  ...  132.666667  2.777778  0.222222  122.888889   \n",
       "1  12.818182  0.000000  0.0  ...  142.454545  4.818182  0.000000  128.636364   \n",
       "2   8.633333  0.000000  0.0  ...  138.666667  1.000000  0.000000  125.666667   \n",
       "3  15.200000  0.000000  0.0  ...  133.000000  4.000000  0.000000  124.000000   \n",
       "4   7.500000  0.000000  0.0  ...  142.000000  4.000000  0.000000  129.000000   \n",
       "\n",
       "         Mean      Median  Variance  NSP  Tendency_0.0  Tendency_1.0  \n",
       "0  121.666667  123.333333  1.555556    N             1             0  \n",
       "1  128.000000  129.818182  3.545455    N             0             1  \n",
       "2  127.666667  128.666667  2.666667    N             1             0  \n",
       "3  122.000000  124.000000  5.000000    N             0             1  \n",
       "4  130.000000  131.000000  2.000000    N             0             1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfd = df2.drop(columns=\"FileName\")\n",
    "dfd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 Split dataframe into features and target<a id='5.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting our features as the X variable, and targets as the y variable for use in our modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfd.drop(columns = ['NSP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dfd['NSP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           LB        AC         FM   UC       ASTV      MSTV      ALTV  \\\n",
      "0  119.333333  0.111111   8.000000  0.0  53.555556  0.655556  8.333333   \n",
      "1  123.000000  1.727273   2.363636  0.0  51.818182  0.790909  3.272727   \n",
      "2  121.000000  2.666667   4.000000  0.0  55.333333  0.566667  2.666667   \n",
      "3  120.000000  0.000000   8.500000  0.0  54.000000  0.850000  0.000000   \n",
      "4  124.000000  3.000000  10.000000  1.0  46.000000  0.800000  0.000000   \n",
      "\n",
      "        MLTV        DL   DS  ...        Min         Max      Nmax    Nzeros  \\\n",
      "0  10.433333  0.111111  0.0  ...  85.777778  132.666667  2.777778  0.222222   \n",
      "1  12.818182  0.000000  0.0  ...  64.636364  142.454545  4.818182  0.000000   \n",
      "2   8.633333  0.000000  0.0  ...  98.666667  138.666667  1.000000  0.000000   \n",
      "3  15.200000  0.000000  0.0  ...  60.000000  133.000000  4.000000  0.000000   \n",
      "4   7.500000  0.000000  0.0  ...  90.000000  142.000000  4.000000  0.000000   \n",
      "\n",
      "         Mode        Mean      Median  Variance  Tendency_0.0  Tendency_1.0  \n",
      "0  122.888889  121.666667  123.333333  1.555556             1             0  \n",
      "1  128.636364  128.000000  129.818182  3.545455             0             1  \n",
      "2  125.666667  127.666667  128.666667  2.666667             1             0  \n",
      "3  124.000000  122.000000  124.000000  5.000000             0             1  \n",
      "4  129.000000  130.000000  131.000000  2.000000             0             1  \n",
      "\n",
      "[5 rows x 22 columns] 0    N\n",
      "1    N\n",
      "2    N\n",
      "3    N\n",
      "4    N\n",
      "Name: NSP, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.head(),y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    238\n",
       "P     23\n",
       "Name: NSP, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Preliminary modeling<a id='5.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by training a single model on a single set of parameters, to see what non-tuned results might look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    166\n",
       "P     16\n",
       "Name: NSP, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    72\n",
       "P     7\n",
       "Name: NSP, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class imbalance is roughly 10:1 in favor of the negative class (N)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a fortuitous stroke of pure coincidence, the negative class is \"N\" for \"Normal\", and the positive class is \"P\" for \"Pathological\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3 Scaling the data<a id='5.3'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the data containing vastly different scales, we will use Standard Scaler to ensure all of the data have equal footing, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sX_train = pd.DataFrame(sc.fit_transform(X_train),columns=X_train.columns)\n",
    "sX_test = pd.DataFrame(sc.transform(X_test),columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4 Running a logistic regression model as a test<a id='5.4'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver = 'saga', penalty = 'l2', max_iter = 5000, C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100, max_iter=5000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100, max_iter=5000, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100, max_iter=5000, solver='saga')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(sX_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <td>0.233646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>-1.263528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FM</th>\n",
       "      <td>0.221550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UC</th>\n",
       "      <td>-2.106855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASTV</th>\n",
       "      <td>3.834073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSTV</th>\n",
       "      <td>-0.212093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALTV</th>\n",
       "      <td>1.819966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLTV</th>\n",
       "      <td>-0.608797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>-0.279079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DS</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DP</th>\n",
       "      <td>2.378448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width</th>\n",
       "      <td>1.209182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>-1.117534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.810938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nmax</th>\n",
       "      <td>-1.773047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nzeros</th>\n",
       "      <td>0.070389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mode</th>\n",
       "      <td>-0.088515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>-0.547226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median</th>\n",
       "      <td>-0.576969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variance</th>\n",
       "      <td>2.037577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tendency_0.0</th>\n",
       "      <td>0.129191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tendency_1.0</th>\n",
       "      <td>0.057786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "LB            0.233646\n",
       "AC           -1.263528\n",
       "FM            0.221550\n",
       "UC           -2.106855\n",
       "ASTV          3.834073\n",
       "MSTV         -0.212093\n",
       "ALTV          1.819966\n",
       "MLTV         -0.608797\n",
       "DL           -0.279079\n",
       "DS            0.000000\n",
       "DP            2.378448\n",
       "Width         1.209182\n",
       "Min          -1.117534\n",
       "Max           0.810938\n",
       "Nmax         -1.773047\n",
       "Nzeros        0.070389\n",
       "Mode         -0.088515\n",
       "Mean         -0.547226\n",
       "Median       -0.576969\n",
       "Variance      2.037577\n",
       "Tendency_0.0  0.129191\n",
       "Tendency_1.0  0.057786"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcoef = pd.DataFrame(lr.coef_,columns=X_train.columns).T\n",
    "dfcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tr = lr.predict(sX_train)\n",
    "y_pred = lr.predict(sX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00       166\n",
      "           P       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00       182\n",
      "   macro avg       1.00      1.00      1.00       182\n",
      "weighted avg       1.00      1.00      1.00       182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Training Data\")\n",
    "print(classification_report(y_train, y_pred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99        72\n",
      "           P       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.99        79\n",
      "   macro avg       0.94      0.99      0.96        79\n",
      "weighted avg       0.99      0.99      0.99        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Test Data\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of our initial algorithm show excellent performance on the training set - as we would expect - and unusually decent performance on the test set. This is likely partially a product of the fact that we only have 7 positive test samples to work with when using 70% training size split.\n",
    "\n",
    "Setting aside (for now) continued suspicions regarding the performance of a simple model on the data, we continue on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the small size of the overall dataset, and the small size of the positive class, we will need to use oversampling techniques as part of our process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0 Applying the Machine Learning models<a id='6.0'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a supervised classification problem, we can use the following classification models:\n",
    "* Logistic Regression\n",
    "* Random Forest\n",
    "* K-Nearest Neighbor (KNN)\n",
    "* Support vector machine (SVM)\n",
    "* Naive Bayes\n",
    "* Gradient Boost\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, however, we can use oversampling techniques to make our small dataset seem larger, and possible improve the fit of our models by making new datapoints using the old ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 Oversampling<a id='6.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, certain oversampling methods may help to increase the goodness of fit for our data, resulting in algorithms that produce more accurate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python library scikit learn has many available oversampling methods available. We will utilize RandomOverSampler and multiple varieties of Synthetic Minority Over-sampling Technique (SMOTE) such as BorderlineSMOTE, SMOTENC, ADASYN, KMeansSMOTE, SVMSMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, a function is used to loop through the different oversampling techniques, while also testing the performance of models fit to that oversampled data. For this part, we will utilize Logistic Regression and Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(X_train, X_test, y_train, y_test, cat_feat,score):\n",
    "    \n",
    "    \"\"\"\n",
    "    cat_feat is a list of categorical features by column index\n",
    "    \n",
    "    score is what output is desired, with choices:\n",
    "        \"N-precision\" \n",
    "        \"N-recall\"\n",
    "        \"P-precision\"\n",
    "        \"P-recall\"\n",
    "    \"\"\"\n",
    "    \n",
    "    #use pre-scaled data\n",
    "    \n",
    "    \n",
    "    #code to time how long this code runs for\n",
    "    start_timeLR = datetime.now()\n",
    "    \n",
    "    from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SMOTENC, ADASYN, RandomOverSampler, KMeansSMOTE, SVMSMOTE\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    resamplers = [None, RandomOverSampler(), BorderlineSMOTE(), SMOTENC(categorical_features=cat_feat), ADASYN(), KMeansSMOTE(), SVMSMOTE()]\n",
    "    algos = [LogisticRegression(solver = 'saga', penalty = 'l2', max_iter = 5000, C=100),\n",
    "             RandomForestClassifier()]\n",
    "    cr = []\n",
    "    cols = []\n",
    "    for r in resamplers:\n",
    "        if r is not None:\n",
    "            # fit the model\n",
    "            X,y = r.fit_resample(X_train, y_train)\n",
    "            print('______________________________________')\n",
    "            print('______________________________________')\n",
    "            print('\\nResampler = ',r)\n",
    "\n",
    "            for algo in algos:\n",
    "                a = algo\n",
    "                a.fit(X,y)\n",
    "                y_pred = a.predict(X_test)\n",
    "                clrepd = classification_report(y_test, y_pred, output_dict=True)\n",
    "                clrep = classification_report(y_test, y_pred)\n",
    "                cr.append(clrepd)\n",
    "\n",
    "                cols.append('{} {}'.format(r,a))\n",
    "\n",
    "                print('*************')\n",
    "                print('Algorithm = ',a)\n",
    "                print(\"Classification Report for Test Data\")\n",
    "                print(clrep)\n",
    "        else:\n",
    "            X,y = X_train, y_train\n",
    "            print('______________________________________')\n",
    "            print('______________________________________')\n",
    "            print('\\nResampler = ',r)\n",
    "\n",
    "            for algo in algos:\n",
    "                a = algo\n",
    "                a.fit(X,y)\n",
    "                y_pred = a.predict(X_test)\n",
    "                clrepd = classification_report(y_test, y_pred, output_dict=True)\n",
    "                clrep = classification_report(y_test, y_pred)\n",
    "                cr.append(clrepd)\n",
    "\n",
    "                cols.append('{} {}'.format(r,a))\n",
    "\n",
    "                print('*************')\n",
    "                print('Algorithm = ',a)\n",
    "                print(\"Classification Report for Test Data\")\n",
    "                print(clrep)\n",
    "            \n",
    "    crd = pd.DataFrame(cr, index=cols).T\n",
    "    \n",
    "    \n",
    "    Nprecision = []\n",
    "    Nrecall = []\n",
    "    Pprecision = []\n",
    "    Precall = []\n",
    "    for i in crd.iloc[0]:\n",
    "        Nprecision.append(i['precision'])\n",
    "        Nrecall.append(i['recall'])\n",
    "    for i in crd.iloc[1]:\n",
    "        Pprecision.append(i['precision'])\n",
    "        Precall.append(i['recall'])\n",
    "    \n",
    "    Npdf = pd.DataFrame(Nprecision, index=cols, columns = [score]).T\n",
    "    Nrdf = pd.DataFrame(Nrecall, index=cols, columns = [score]).T\n",
    "    Ppdf = pd.DataFrame(Pprecision, index=cols, columns = [score]).T\n",
    "    Prdf = pd.DataFrame(Precall, index=cols, columns = [score]).T\n",
    "    \n",
    "    \n",
    "    end_timeLR = datetime.now()\n",
    "    print('Duration of this segment: {}'.format(end_timeLR - start_timeLR))\n",
    "    if score == \"N-precision\":\n",
    "        return Npdf\n",
    "    elif score == \"N-recall\":\n",
    "        return Nrdf\n",
    "    elif score == \"P-precision\":\n",
    "        return Ppdf\n",
    "    elif score == \"P-recall\":\n",
    "        return Prdf\n",
    "    else:\n",
    "        return crd\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our main concern is having a high recall for the positive class \"P\", we will focus on recall as our scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________\n",
      "______________________________________\n",
      "\n",
      "Resampler =  None\n",
      "*************\n",
      "Algorithm =  LogisticRegression(C=100, max_iter=5000, solver='saga')\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99        72\n",
      "           P       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.99        79\n",
      "   macro avg       0.94      0.99      0.96        79\n",
      "weighted avg       0.99      0.99      0.99        79\n",
      "\n",
      "*************\n",
      "Algorithm =  RandomForestClassifier()\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99        72\n",
      "           P       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.99        79\n",
      "   macro avg       0.94      0.99      0.96        79\n",
      "weighted avg       0.99      0.99      0.99        79\n",
      "\n",
      "______________________________________\n",
      "______________________________________\n",
      "\n",
      "Resampler =  RandomOverSampler()\n",
      "*************\n",
      "Algorithm =  LogisticRegression(C=100, max_iter=5000, solver='saga')\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.97      0.99        72\n",
      "           P       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.97        79\n",
      "   macro avg       0.89      0.99      0.93        79\n",
      "weighted avg       0.98      0.97      0.98        79\n",
      "\n",
      "*************\n",
      "Algorithm =  RandomForestClassifier()\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00        72\n",
      "           P       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       1.00      1.00      1.00        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "______________________________________\n",
      "______________________________________\n",
      "\n",
      "Resampler =  BorderlineSMOTE()\n",
      "*************\n",
      "Algorithm =  LogisticRegression(C=100, max_iter=5000, solver='saga')\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99        72\n",
      "           P       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.99        79\n",
      "   macro avg       0.94      0.99      0.96        79\n",
      "weighted avg       0.99      0.99      0.99        79\n",
      "\n",
      "*************\n",
      "Algorithm =  RandomForestClassifier()\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99        72\n",
      "           P       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.99        79\n",
      "   macro avg       0.94      0.99      0.96        79\n",
      "weighted avg       0.99      0.99      0.99        79\n",
      "\n",
      "______________________________________\n",
      "______________________________________\n",
      "\n",
      "Resampler =  SMOTENC(categorical_features=[20, 21])\n",
      "*************\n",
      "Algorithm =  LogisticRegression(C=100, max_iter=5000, solver='saga')\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99        72\n",
      "           P       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.99        79\n",
      "   macro avg       0.94      0.99      0.96        79\n",
      "weighted avg       0.99      0.99      0.99        79\n",
      "\n",
      "*************\n",
      "Algorithm =  RandomForestClassifier()\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00        72\n",
      "           P       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       1.00      1.00      1.00        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "______________________________________\n",
      "______________________________________\n",
      "\n",
      "Resampler =  ADASYN()\n",
      "*************\n",
      "Algorithm =  LogisticRegression(C=100, max_iter=5000, solver='saga')\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.97      0.99        72\n",
      "           P       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.97        79\n",
      "   macro avg       0.89      0.99      0.93        79\n",
      "weighted avg       0.98      0.97      0.98        79\n",
      "\n",
      "*************\n",
      "Algorithm =  RandomForestClassifier()\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00        72\n",
      "           P       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       1.00      1.00      1.00        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "______________________________________\n",
      "______________________________________\n",
      "\n",
      "Resampler =  KMeansSMOTE()\n",
      "*************\n",
      "Algorithm =  LogisticRegression(C=100, max_iter=5000, solver='saga')\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99        72\n",
      "           P       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.99        79\n",
      "   macro avg       0.94      0.99      0.96        79\n",
      "weighted avg       0.99      0.99      0.99        79\n",
      "\n",
      "*************\n",
      "Algorithm =  RandomForestClassifier()\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00        72\n",
      "           P       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       1.00      1.00      1.00        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "______________________________________\n",
      "______________________________________\n",
      "\n",
      "Resampler =  SVMSMOTE()\n",
      "*************\n",
      "Algorithm =  LogisticRegression(C=100, max_iter=5000, solver='saga')\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      0.99      0.99        72\n",
      "           P       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.99        79\n",
      "   macro avg       0.94      0.99      0.96        79\n",
      "weighted avg       0.99      0.99      0.99        79\n",
      "\n",
      "*************\n",
      "Algorithm =  RandomForestClassifier()\n",
      "Classification Report for Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00        72\n",
      "           P       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       1.00      1.00      1.00        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n",
      "Duration of this segment: 0:00:02.863907\n"
     ]
    }
   ],
   "source": [
    "P_recall = oversample(sX_train, sX_test, y_train, y_test,cat_feat=[20,21], score=\"P-recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <th>None RandomForestClassifier()</th>\n",
       "      <th>RandomOverSampler() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <th>RandomOverSampler() RandomForestClassifier()</th>\n",
       "      <th>BorderlineSMOTE() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <th>BorderlineSMOTE() RandomForestClassifier()</th>\n",
       "      <th>SMOTENC(categorical_features=[20, 21]) LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <th>SMOTENC(categorical_features=[20, 21]) RandomForestClassifier()</th>\n",
       "      <th>ADASYN() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <th>ADASYN() RandomForestClassifier()</th>\n",
       "      <th>KMeansSMOTE() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <th>KMeansSMOTE() RandomForestClassifier()</th>\n",
       "      <th>SVMSMOTE() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <th>SVMSMOTE() RandomForestClassifier()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P-recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          None LogisticRegression(C=100, max_iter=5000, solver='saga')  \\\n",
       "P-recall                                                1.0              \n",
       "\n",
       "          None RandomForestClassifier()  \\\n",
       "P-recall                            1.0   \n",
       "\n",
       "          RandomOverSampler() LogisticRegression(C=100, max_iter=5000, solver='saga')  \\\n",
       "P-recall                                                1.0                             \n",
       "\n",
       "          RandomOverSampler() RandomForestClassifier()  \\\n",
       "P-recall                                           1.0   \n",
       "\n",
       "          BorderlineSMOTE() LogisticRegression(C=100, max_iter=5000, solver='saga')  \\\n",
       "P-recall                                                1.0                           \n",
       "\n",
       "          BorderlineSMOTE() RandomForestClassifier()  \\\n",
       "P-recall                                         1.0   \n",
       "\n",
       "          SMOTENC(categorical_features=[20, 21]) LogisticRegression(C=100, max_iter=5000, solver='saga')  \\\n",
       "P-recall                                                1.0                                                \n",
       "\n",
       "          SMOTENC(categorical_features=[20, 21]) RandomForestClassifier()  \\\n",
       "P-recall                                                1.0                 \n",
       "\n",
       "          ADASYN() LogisticRegression(C=100, max_iter=5000, solver='saga')  \\\n",
       "P-recall                                                1.0                  \n",
       "\n",
       "          ADASYN() RandomForestClassifier()  \\\n",
       "P-recall                                1.0   \n",
       "\n",
       "          KMeansSMOTE() LogisticRegression(C=100, max_iter=5000, solver='saga')  \\\n",
       "P-recall                                                1.0                       \n",
       "\n",
       "          KMeansSMOTE() RandomForestClassifier()  \\\n",
       "P-recall                                     1.0   \n",
       "\n",
       "          SVMSMOTE() LogisticRegression(C=100, max_iter=5000, solver='saga')  \\\n",
       "P-recall                                                1.0                    \n",
       "\n",
       "          SVMSMOTE() RandomForestClassifier()  \n",
       "P-recall                                  1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A frustratingly accurate result has occured. A few of the models score 100% for accuracy, precision, recall, and f1. This is simply not a realistic result.\n",
    "\n",
    "Another way to demonstrate the performance of each oversampling technique is to leave the test data alone and instead split the training data into k-1 y-stratified groups, leaving a validation set to test on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to accomplish this, I created a similar function which takes the mean cross-validation recall score of 3 k-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampleK(X_train, X_test, y_train, y_test, cat_feat):\n",
    "    \n",
    "    \"\"\"\n",
    "    cat_feat is a list of categorical features by column index\n",
    "    \n",
    "    scoring is recall\n",
    "    \"\"\"\n",
    "    \n",
    "    #use pre-scaled data\n",
    "    \n",
    "    \n",
    "    #code to time how long this code runs for\n",
    "    start_timeLR = datetime.now()\n",
    "    from sklearn.model_selection import cross_validate, cross_val_score\n",
    "    from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SMOTENC, ADASYN, RandomOverSampler, KMeansSMOTE, SVMSMOTE\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    resamplers = [None, RandomOverSampler(), BorderlineSMOTE(), SMOTENC(categorical_features=cat_feat), ADASYN(), KMeansSMOTE(), SVMSMOTE()]\n",
    "    algos = [LogisticRegression(solver = 'saga', penalty = 'l2', max_iter = 5000, C=100),\n",
    "             RandomForestClassifier()]\n",
    "    cvs = []\n",
    "    cols = []\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    \n",
    "    \n",
    "    for r in resamplers:\n",
    "        if r is not None:\n",
    "            # fit the model\n",
    "            X,y = r.fit_resample(X_train, y_train)\n",
    "\n",
    "            for algo in algos:\n",
    "                al = algo\n",
    "                cv_r = np.mean(cross_val_score(al, X,y, scoring=\"recall_macro\",\n",
    "                    cv=StratifiedKFold(n_splits=3, shuffle=True)))\n",
    "                cvs.append(cv_r)\n",
    "                cols.append('{} {}'.format(r,al))\n",
    "\n",
    "        else:\n",
    "            X,y = X_train, y_train\n",
    "\n",
    "            for algo in algos:\n",
    "                al = algo\n",
    "                cv_r = np.mean(cross_val_score(al, X,y, scoring=\"recall_macro\",\n",
    "                    cv=StratifiedKFold(n_splits=3, shuffle=True)))\n",
    "                cvs.append(cv_r)\n",
    "                cols.append('{} {}'.format(r,al))\n",
    "            \n",
    "    crd = pd.DataFrame(cvs, index=cols, columns = ['Recall Score'])\n",
    "    \n",
    "\n",
    "    \n",
    "    end_timeLR = datetime.now()\n",
    "    print('Duration of this segment: {}'.format(end_timeLR - start_timeLR))\n",
    "    \n",
    "    return crd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of this segment: 0:00:04.857023\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <td>0.935462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None RandomForestClassifier()</th>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomOverSampler() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <td>0.987933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomOverSampler() RandomForestClassifier()</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BorderlineSMOTE() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <td>0.987987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BorderlineSMOTE() RandomForestClassifier()</th>\n",
       "      <td>0.991017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTENC(categorical_features=[20, 21]) LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <td>0.985011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTENC(categorical_features=[20, 21]) RandomForestClassifier()</th>\n",
       "      <td>0.993939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADASYN() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <td>0.981872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADASYN() RandomForestClassifier()</th>\n",
       "      <td>0.993939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeansSMOTE() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <td>0.987933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMeansSMOTE() RandomForestClassifier()</th>\n",
       "      <td>0.987987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSMOTE() LogisticRegression(C=100, max_iter=5000, solver='saga')</th>\n",
       "      <td>0.985011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSMOTE() RandomForestClassifier()</th>\n",
       "      <td>0.997024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Recall Score\n",
       "None LogisticRegression(C=100, max_iter=5000, s...      0.935462\n",
       "None RandomForestClassifier()                           0.783333\n",
       "RandomOverSampler() LogisticRegression(C=100, m...      0.987933\n",
       "RandomOverSampler() RandomForestClassifier()            1.000000\n",
       "BorderlineSMOTE() LogisticRegression(C=100, max...      0.987987\n",
       "BorderlineSMOTE() RandomForestClassifier()              0.991017\n",
       "SMOTENC(categorical_features=[20, 21]) Logistic...      0.985011\n",
       "SMOTENC(categorical_features=[20, 21]) RandomFo...      0.993939\n",
       "ADASYN() LogisticRegression(C=100, max_iter=500...      0.981872\n",
       "ADASYN() RandomForestClassifier()                       0.993939\n",
       "KMeansSMOTE() LogisticRegression(C=100, max_ite...      0.987933\n",
       "KMeansSMOTE() RandomForestClassifier()                  0.987987\n",
       "SVMSMOTE() LogisticRegression(C=100, max_iter=5...      0.985011\n",
       "SVMSMOTE() RandomForestClassifier()                     0.997024"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampleK(sX_train, sX_test, y_train, y_test, cat_feat=[20,21])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2 Final realizations about the data<a id='6.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this juncture, it still appears as though there is a problem with the data. Some of the models, without even the benefit of hyperparameter tuning, are able to achieve perfect recall - an extremely unlikely outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, upon further inspection of the raw data, I discovered that the researchers responsible for the dataset made an unintelligable decision regarding their samples. In the prior notebook, we discovered that single patients had multiple entries for CTG results. This time, after really digging into the raw data, I discovered two things: \n",
    "1. The entries corresponding to each patient were not unique CTG instances at all. They overlapped in time. Some of the datapoints encompassed entirely the rest of that patient's data.\n",
    "2. Some unseen data leakage is continuing to occur, even after the fixes we established."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to reach out to the authors of the original study (who would have overseen data collection), but they never responded. This was a piece of research done more than 20 years ago in Portugal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a fellow published author of research, and without intending to denigrate the work done by these individuals, I would make this assessment: in this situation, everything from the data collection process to the writing of the research article was not on par with scientific standards.\n",
    "\n",
    "The most confusing aspect of this scenario is this dataset's inclusion in the UCI Machine Learning Repository. The data is presented as 2126 unique datapoints ripe for machine learning classification algorithms. However, the real number of actionable unique datapoints is a mere fraction of that, and the way it was collected makes impossible the interpretation of the data values presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this project was an assignment from an employer, my report would include the aforementioned analysis, as well as subsequent strong suggestions for data collection improvements and the implementation of a strict, simple, standard process for data collection and entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.0 Conclusion<a id='7.0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After noticing a problem with data leakage in the previous notebook (Preprocessing and Training), we decided to \"start over\" in this \"Modeling\" notebook.\n",
    "\n",
    "We began by importing the necessary modules and uploading the data.\n",
    "\n",
    "Then, after inspecting the data, we eliminated excess info from the data and pruned the data down to features and target.\n",
    "\n",
    "As a remedial step, we then grouped and aggregated the data in order to eliminate data leakage caused by the poor construction of this dataset.\n",
    "\n",
    "After encoding the categorical independent variable and visualizing the target, the last of the data editing occured as the subject identification column was removed.\n",
    "\n",
    "We started the modeling process as normal, with a train/test split followed by feature scaling.\n",
    "\n",
    "Recall was the chosen performance metric due to the nature of our designated problem.\n",
    "\n",
    "Then we ran a simple logistic regression in order to establish a starting point.\n",
    "\n",
    "However, the test data performed very well. Our suspicions were raised regarding continued data leakage.\n",
    "\n",
    "Continuing on in the event that the data was somehow good, we applied oversampling techniques due to the imbalanced nature of our target class (10:1).\n",
    "\n",
    "Using cross-validation with stratified K-fold, we saw that BorderlineSMOTE, SMOTENC, ADASYN, RandomOverSampler, KMeansSMOTE, and SVMSMOTE all performed extremely well on recall. Unfortunately, some of the models achieved a perfect recall score. This was the proverbial 'straw that broke the camel's back' for my efforts. In consultation with my advisor, discussing this scenario as a potential real-life disappointment, we agreed to close down the project due to bad data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we tried to overcome a poorly constructed dataset by reducing the obvious data leakage. After attempting to model the fixed data, we still found the results to be too exemplary to be real. Unfortunately, for this reason, this project needs to come to an end without a fulfilling conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
